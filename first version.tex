
\documentclass[12pt]{iopart}
\pdfoutput=1
\usepackage{iopams}
\usepackage{amssymb, epsfig}
%\usepackage{amsmath, amssymb,epsfig}
\usepackage{latexsym}

%\usepackage[hypertex,hyperindex]{hyperref}
%\usepackage{showkeys}
\usepackage{graphicx}
\usepackage{color}

\newcommand{\pf}{\mbox{pf}}

\begin{document}

\bibliographystyle{plain}
\def\debproof{\noindent {\bf Proof.} }
\def\finproof{\hfill {\small $\Box$} \\}
%\renewcommand{\theequation}{\arabic{section}.\arabic{equation}}

\makeatletter % `@' now normal "letter"
\@addtoreset{equation}{section}
\makeatother  % `@' is restored as "non-letter"
\renewcommand\theequation{{\thesection}.{\arabic{equation}}}
\title[RTM in the Elastic Medium Half Space]{Reverse Time Migration for Extended Obstacles in the Half Space: Elastic Waves}
\author{ Zhiming Chen, Shiqi Zhou }
\address{LSEC, Institute of Computational Mathematics, Academy of
	Mathematics and Systems Science, Chinese Academy of Sciences,
	Beijing 100190, China}

\begin{abstract}
	We consider a reverse time migration method for reconstructing extended
	obstacles in the half space with finite aperture data using elastic waves at a fixed
	frequency. We prove the resolution of the reconstruction method in terms of the
	aperture and the depth of the obstacle embedded in the half space. The resolution
	analysis implies that the imaginary part of the cross-correlation imaging function
	always peaks on the illuminated boundary of the obstacle. Numerical experiments
	are included to illustrate the powerful imaging quality and to confirm our resolution
	results. 
\end{abstract}
\maketitle
\newcommand{\eps}{\varepsilon}
\newcommand{\RR}{\mathcal{R}}
\newtheorem{lem}{Lemma}[section]
\newtheorem{prop}{Proposition}[section]
\newtheorem{cor}{Corollary}[section]
\newtheorem{thm}{Theorem}[section]
\newtheorem{rem}{Remark}[section]
\newtheorem{alg}{Algorithm}[section]
\newtheorem{assum}{Assumption}[section]
\newtheorem{definition}{Definition}[section]


\newcounter{RomanNumber}
\newcommand{\MyRoman}[1]{\rm\setcounter{RomanNumber}{#1}\Roman{RomanNumber}}

\newcommand{\bL}{\mathbf{L}}
\newcommand{\bH}{\mathbf{H}}
\newcommand{\bW}{\mathbf{W}}
\newcommand{\bP}{\mathbf{P}}
\newcommand{\bQ}{\mathbf{Q}}
\newcommand{\bp}{\mathbf{p}}
\newcommand{\bq}{\mathbf{q}}
\newcommand{\uL}{u_{_{\rm L}}}
\newcommand{\vL}{v_{_{\rm L}}}
\newcommand{\tuL}{\tilde u_{_{\rm L}}}
\newcommand{\tvL}{\tilde v_{_{\rm L}}}
\newcommand{\fL}{f_{_{\rm L}}}
\newcommand{\gL}{g_{_{\rm L}}}
\newcommand{\bpL}{\bp_{_{\rm L}}}
\newcommand{\bqL}{\bq_{_{\rm L}}}
\newcommand{\tbpL}{\tilde{\bp}_{_{\rm L}}}
\newcommand{\tbqL}{\tilde{\bq}_{_{\rm L}}}
\newcommand{\tbpLf}{\tilde{\bp}_{_{\rm L,1}}}
\newcommand{\tbpLs}{\tilde{\bp}_{_{\rm L,2}}}
\newcommand{\tbqLf}{\tilde{\bq}_{_{\rm L,1}}}
\newcommand{\tbqLs}{\tilde{\bq}_{_{\rm L,2}}}
\newcommand{\bn}{\nu}
\newcommand{\bv}{\mathbf{v}}
\newcommand{\om}{\omega}
\newcommand{\pa}{\partial}
\newcommand{\la}{\langle}
\newcommand{\ra}{\rangle}
\newcommand{\lla}{\la{\hskip -2pt}\la}
\newcommand{\rra}{\ra{\hskip -2pt}\ra}
\newcommand{\jj}{\|{\hskip -0.8pt} |}
\newcommand{\al}{\alpha}
\newcommand{\ze}{\zeta}
\newcommand{\si}{\sigma}
\newcommand{\ep}{\varepsilon}
\newcommand{\na}{\nabla}
\newcommand{\vp}{\varphi}
\newcommand{\ga}{\gamma}
\newcommand{\Ga}{\Gamma}
\newcommand{\Om}{\Omega}
\newcommand{\de}{\delta}
\newcommand{\Th}{\Theta}
\newcommand{\De}{\Delta}
\newcommand{\Lam}{\Lambda}
\newcommand{\lam}{\lambda}
\newcommand{\tri}{\triangle}
\newcommand{\lj}{[{\hskip -2pt} [}
\newcommand{\rj}{]{\hskip -2pt} ]}
\newcommand{\bks}{\backslash}
%\newcommand{\diag}{\mathrm{diag}}
\newcommand{\diam}{\mathrm{diam}}
\newcommand{\osc}{\mathrm{osc}}
\newcommand{\meas}{\mathrm{meas}}
\newcommand{\dist}{\mathrm{dist}}

\newcommand{\mL}{\mathscr{L}}
\newcommand{\cT}{{\cal T}}
\newcommand{\cM}{{\cal M}}
\newcommand{\cE}{{\cal E}}
\newcommand{\cL}{{\cal L}}
\newcommand{\cF}{{\cal F}}
\newcommand{\cB}{{\cal B}}
\newcommand{\PML}{{\rm PML}}
\newcommand{\FEM}{{\rm FEM}}
\newcommand{\rd}{\,\mathrm{d}}

\renewcommand{\i}{\mathbf{i}}
\renewcommand{\v}{\mathbf{v}}
\renewcommand{\u}{\mathbf{u}}
\renewcommand{\r}{\mathbf{r}}
\newcommand{\R}{{\mathbb{R}}}
\newcommand{\Z}{{\mathbb{Z}}}
\newcommand{\C}{{\mathbb{C}}}
\newcommand{\I}{{\mathbb{I}}}
\renewcommand{\Re}{\mathrm{Re}\,}
\renewcommand{\Im}{\mathrm{Im}\,}
\renewcommand{\div}{\mathrm{div}}
\newcommand{\curl}{\mathrm{curl}}
\newcommand{\Curl}{\mathbf{curl}}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newcommand{\be}{\begin{eqnarray}}
\newcommand{\ee}{\end{eqnarray}}
\newcommand{\ben}{\begin{eqnarray*}}
\newcommand{\een}{\end{eqnarray*}}
\newcommand{\nn}{\nonumber}

\section{Introduction}\label{section1}
In this paper we study a reverse time migration (RTM) algorithm to find the support of an unknown obstacle in the half space from the measurement of scattered waves on the boundary of the half space which is far away from the obstacle. The physical properties of the obstacle such as penetrable or non-penetrable, and for non-penetrable obstacles, the type of boundary conditions on the boundary of the obstacle, are not required in the algorithm.

Let the non-penetrable obstacle occupy a bounded Lipschitz domain $D\subset\R_+^2$ with $\nu$ the unit outer normal to its boundary $\Ga_D$. We
assume the incident wave is emitted by a point source located at $x_s$, explosive along the polarization direction $q\in\R^2$, on the surface $\Ga_0=\{(x_1,x_2)^T:x_1\in\R,x_2=0\}$ which is far away from the obstacle. The measured data $u_q$ corresponding to the polarization direction $q$ is the solution of the following elastic scattering problem in the isotropic homogeneous medium half space with \emph{Lam\'{e}} constant $\lambda$ and $\mu$ and constant density $\rho\equiv1$:
\be\label{eq1.1}
& &\nabla\cdot\sigma(u_q) + \rho\omega^2u_q= -\delta_{x_s}(x)q \ \ \ \ \mbox{in }\R_+^2\bks \bar{D}\\
& &u_q=0 \ \ \mbox{on} \ \Ga_D  \ \ \mbox{and} \ \ \sigma(u_q)\cdot e_2=0 \ \ \mbox{on} \ \Ga_0
\ee
together with the constitutive relation (Hookes law)
\ben
\sigma(u_q) = 2\mu\varepsilon(u_q) + \lambda\div u_q \I \\
\varepsilon(u_q)=\frac{1}{2}(\na u_q +(\na u_q)^T)
\een
where $\omega$ is the circular frequency, $u_q(x)\in\C^2$ denotes the displacement fields and $\sigma$ is the stress tensor. We also need to define the surface traction $T_x^n (\cdot)$ on the normal direction n,
\ben
T_x^n u(x) := \sigma\cdot n = 2\mu\frac{\pa u}{\pa n}+\lambda n\div u + \mu n \times \curl u
\een
For simplicity, let's introduce \emph{Lam\'{e}} operator $\Delta_e$ as
\ben
\Delta_e u = (\lambda+2\mu)\nabla\nabla\cdot u - \mu\nabla\times\nabla\times u=\nabla\cdot\sigma(u)
\een
The equation (\ref{eq1.1}) is understood as the limit when $x_s\in\R_+^2\bks \bar{D}$ tends to $\Ga_0$ whose precise meaning will be given below after we introduce the Neumann Green Tensor and the definition of the radiation condition.

The reverse time migration (RTM) method, which consists of back-propagating
the complex conjugated data into the background medium and computing the crosscorrelation between the incident wave field and the backpropagated field to output the
final imaging profile, is nowadays widely used in exploration geophysics \cite{berkhout2012seismic,bleistein2013mathematics,claerbout1985imaging}. In \cite{chen2013reverse_acou,chen2013reverse_elec},
the RTM method for reconstructing extended targets using acoustic and electromagnetic
waves at a fixed frequency in the free space is proposed and studied. The resolution
analysis in \cite{chen2013reverse_acou,chen2013reverse_elec} is achieved without using the small inclusion or geometrical optics
assumption previously made in the literature (e.g. \cite{ammari2013mathematical,bleistein2013mathematics}). In \cite{chen2015reverse_planar}, a new RTM algorithm
is developed for finding extended targets in a planar waveguide which is motivated by
the generalized Helmholtz-Kirchhoff identity for scattering problems in waveguides.

The layout of the paper is as follows. In section 2 we study the two Green Tensor for
the scattering problem in the half space satisfying the homogeneous Neumann condition and Dirichlet condition on $\Ga_0$. We recall the derivation of the Green
Tensor by the method of Fourier transform and derive an alternative form of the
Green Tensor which is crucial for the analysis in the rest. In section 3 we introduce the RTM
algorithm. In section 4 we study the point spread function. In section 5 we study
the resolution analysis of the RTM method. In section 6
we report extensive numerical experiments to show the competitive performance of the
RTM algorithm.



\section{Green Tensor in the half space}

In this section we will study the elastic Green Tensor in the half-space with Neumann boundary \cite{nedelec2011}:
\be
& & \De_e N(x;y) + \omega^2 N(x,y) = -\mathbf{\de}_y(x) \mathbb{I} \ \ \ \ \mbox{in} \ \ \  \R^2_+ , \label{eq_n1} \\
& & \sigma_x (N(x,y))e_2 = 0 \ \ \ \ \ \ \mbox{on} \ \ \ x_2=0 \label{eq_n2}
\ee
and with Dirichlet Boundary \cite{arens1999}
\be
& & \De_e D(x,y) + \omega^2 D(x,y) = -\mathbf{\de}_y(x) \mathbb{I} \ \ \ \ \mbox{in} \ \ \  \R^2_+ , \label{eq_d1} \\
& &  D(x,y) = 0 \ \ \ \ \ \ \mbox{on} \ \ \ x_2=0 \label{eq_d2}
\ee
where $\de_y(x)$ is the Dirac source at $y \in R^2_+$ and $N(x,y)$, $D(x,y)$ are $\mathbb{C}^{2\times2}$ matrixes. We will first use Fourier transform to derive the formula of Green Tensor in frequency domain. Let
\be
& & \hat N(\xi,x_2;y_2)= \int^{+\infty}_{-\infty}N(x_1,x_2;y) e^{-\i (x_1-y_1)\xi} dx_1
\ee
By taking the Fourier transform of (\ref{eq_n1}-\ref{eq_n2}), we obtain ODEs for $x_2$ in $R_+$
\be
& & \mu \frac{d^2\hat N_1}{dx_2^2}+\i(\lambda+\mu)\xi\frac{d\hat N_2}{dx_2}+(\omega^2-(\lambda+2\mu)\xi^2)\hat N_1 = [-\de_{y_2}(x_2) , 0] \label{pp3}\\
& & (\lambda+2 \mu)\frac{d^2\hat N_2}{dx_2^2}+\i(\lambda+\mu)\xi\frac{d\hat N_1}{dx_2}+(\omega^2-\mu \xi^2)\hat N_2 = [0 , -\de_{y_2}(x_2)] \label{pp4}
\ee
where $\hat N_i = e_i^T \hat N$ and the boundary coditions on $x_2=0$ are
\be
& & \mu\frac{d\hat N_1}{dx_2}+\i\mu\xi\hat N_2 = [0 , 0] \label{pp5}\\
& & (\lambda+\mu)\frac{d\hat N_2}{dx_2}+\i\lambda\xi\hat N_1 = [0 , 0] \label{pp6}
\ee
For simplicity, the ordinary differential operator and boundary condition in (\ref{pp3}-\ref{pp6}) are denoted as $\mathbb{A}_\xi$ and $\mathbb{B}_\xi$. Now, we recall that
\ben \hspace{-2.5cm}
\hat{\Phi}(\xi,x_2;y_2)=\frac{\i}{2\omega^2}
\Bigg[ \Bigg( \begin{array}{cc}
\mu_s & -\xi\frac{x_2-y_2}{|x_2-y_2|} \\
-\xi\frac{x_2-y_2}{|x_2-y_2|} & \frac{\xi^2}{\mu_s}
\end{array} \Bigg)e^{\i\mu_s|x_2-y_2|} +
\Bigg( \begin{array}{cc}
\frac{\xi^2}{\mu_p} & \xi\frac{x_2-y_2}{|x_2-y_2|} \\
\xi\frac{x_2-y_2}{|x_2-y_2|} & \mu_p
\end{array} \Bigg) e^{\i\mu_p|x_2-y_2|} \Bigg]
\een
Denote $U = \hat N - \hat \Phi$ and it satisifies the following 2-order homogeneous ordinary differential equations with constant coefficients
\be
\mathbb{A}_\xi U^i = 0 \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \  \mbox{in} \ \  \R^2_+ \label{pp7} \\
 \mathbb{B}_\xi U^i= \mathbb{B}_\xi \hat \Phi \ \ \ \ \ \ \ \ \ \ \ \ \ \mbox{on} \ \ x_2=0 \label{pp8}
\ee
where $U^i = U e_i$.

Throughout the paper, we will assume that for $z\in\mathbb{C}$, $z^{1/2}$ is the analytic branch of $\sqrt{z}$ such that $\Im (z^{1/2})\geq0$. This corresponds to the rigt half real axis as the branch cut in the complex plane. For $z=z_1+\mathrm{i}z_2,z_1,z_2\in\mathbb{R}$, we have
\be \label{q1}
z^{1/2}=sgn(z_2)\sqrt{\frac{|z|+z_1}{2}}+\mathrm{i}\sqrt{\frac{|z|-z_1}{2}}
\ee
For $z$ on the right half real axis, we take $z^{1/2}$ as the limit of $(z+\i\varepsilon)^{1/2}$ as $\varepsilon \to 0^+$.


By the standard arguement in ODEs, solutions of (\ref{pp7}) are linear combinations of vectors of the form
\be
\r(x_2) = \v e^{\i\nu x_2}
\ee
where $\mathbf{v} = (v_1,v_2)^T \in \mathbb{C}^2$ and $\nu \in \mathbb{C}$. It is well kown that the admissible values of $\nu$ are in $\Lambda:= \{\pm\mu_p,\pm\mu_s\}$ and where
\be
\mu_\alpha=(k_\alpha^2-\xi^2)^{1/2} \ \ \ \ \ \ \ \ \ \mbox{for} \ \ \ \ \alpha= s,p
\ee

Associated with each value of admissible $\nu\in\Lambda$ there is an eigenvector $\v$. The respective eigenvectors are
\ben
 \v^+_s = \left[ \begin{array}{cc} \i\mu_s \\ -\i\xi \end{array} \right] , \ \ \v^+_p = \left[ \begin{array}{cc} \i\xi \\ \i\mu_p \end{array} \right], \ \ \v^-_s = \left[ \begin{array}{cc} \i\mu_s \\ \i\xi \end{array} \right] ,\  \ \v^-_p = \left[ \begin{array}{cc} -\i\xi \\ \i\mu_p \end{array} \right]
\een
We denote by $\hat{\sigma}(\r)e_2=\u e^{\i\nu x_2}$ the traction of such a vector in the Fourier domain, then we obtain the respective expression for $\v$
\ben\hspace{-1cm}
 \u^+_s = \left[ \begin{array}{cc} -\mu\beta \\ 2\mu\xi\mu_s \end{array} \right] , \  \u^+_p = \left[ \begin{array}{cc} -2\mu\xi\mu_p \\ -\mu\beta \end{array} \right], \  \u^-_s = \left[ \begin{array}{cc} \mu\beta \\ 2\mu\xi\mu_s \end{array} \right] ,\  \u^-_p = \left[ \begin{array}{cc} -2\mu\xi\mu_p \\ \mu\beta \end{array} \right]
\een
where $\beta=k_s^2-2\xi^2$.
By allowing only bounded Fourier modes for the Green function, we must choose $V_S = \v^+_s e^{\i\mu_s x_2}$ and $V_p = \v^+_p e^{\i\mu_p x_2}$. Thus $U_i$ must be written as the linear combination,
\be
U_i = \alpha_i V_s +\beta_i V_p \ \ \ \ \mbox{for} \ \ i=1,2
\ee
Combining (\ref{pp8}) with the linear independence of $V_s , V_p$, then we can obtain $\alpha_i,\beta_i$.

Therefore, the Green Tensor in half-space can be deduced as
\be
\hat N(\xi,x_2;y_2) = \hat \Phi(\xi,x_2;y_2)  -\hat \Phi(\xi,x_2;-y_2) + \hat N_c(\xi,x_2;y_2)
\ee
\be
 \hat
N_c(\xi,x_2;y_2) = &=& \frac{\mathrm{i}}{\omega^2 \delta(\xi)} \Bigg\{ A(\xi)e^{\mathrm{i}\mu_s(x_2+y_2)}+B(\xi)e^{\mathrm{i}\mu_p(x_2+y_2)}\\ \nn
&&+C(\xi)e^{\mathrm{i}\mu_s x_2+\mu_p y_2}+D(\xi)e^{\mathrm{i}\mu_p x_2+\mu_s y_2}\Bigg\}
\ee
where
\ben
	&&{A(\xi)} =
	\left( \begin{array}{ll}
		\mu_s\beta^2 & -4\xi^3\mu_s\mu_p \\
		-\xi\beta^2  & 4\xi_4\mu_p
	\end{array} \right)\ \ \ \ \ \
	{B(\xi)} =
	\left( \begin{array}{ll}
		4\xi^4\mu_s & \xi\beta^2 \\
		4\xi^3\mu_s\mu_p  & \mu_p\beta^2
	\end{array} \right) \\
	&&{C(\xi)} =
	\left( \begin{array}{ll}
		2\xi^2\mu_s\beta & -2\xi\mu_s\mu_p\beta \\
		-2\xi^3\beta  & 2\xi^2\mu_p\beta
	\end{array} \right)\ \
	{D(\xi)} =
	\left( \begin{array}{ll}
		2\xi^2\mu_s\beta & 2\xi^3\beta \\
		2\xi\mu_s\mu_p\beta  & 2\xi^2\mu_p\beta
	\end{array} \right)
\een
and  $\beta(\xi)=k_s^2-2\xi^2$, $\delta(\xi)=\beta^2+4\xi^2\mu_s\mu_p $.

The desired Green function should be obtained by taking the inverse Fourier transform of $\hat N(\xi,x_2;y_2)$. Unfortunately, one cannot simply take the inverse Fourier transform in the above formula because $\delta(\xi)$ have zero points in the real axis by lemma \ref{lem2.1} \cite{achenbach1980}\cite{Harris2001Linear}.
\begin{lem} \label{lem2.1}
	Let \emph{Lam\'{e}} constant $\lambda, \mu \in \R^+$, then the Rayleigh equation $\delta(\xi) = 0$ has only two roots denoted by $\pm k_R$ in complex plane. Morever, $k_R > k_s > k_p, \ k_R\in\R$ and $k_R$ is called Rayleigh wave number.
\end{lem}
\debproof
For the sake of completeness, we include a proof here. It is well known that
\be
\delta(\xi)=(k_s^2-2\xi^2)^2+4\xi^2(k_s^2-\xi^2)^{1/2}(k_p^2-\xi^2)^{1/2}
\ee
However, $\delta(\xi)$ is rendered single-valued by selecting
branch cuts along $k_p<\Re(\xi)<k_s,\Im(\xi)=0$ which is consistent with the convention (\ref{q1}). A simple computation show that $\delta(\pm k_s)>0$ and $\delta(\pm\infty+0\i)<0$. By the continuity of $\delta(\xi)$, we can obtain that it has at least two real zero points which denoted by $\pm k_R$.

Now it turn to proof that $\delta(\xi)$ has only two roots in the complex plane by the principle of arguement which follows as a theorem of the theory of complex variables\cite{Ahlfors1979Complex}. Now consider the contour $C$ consisting of $\Ga$, and $C_l$ and $C_r$ where $C_r=[k_p+\i0^+,k_s+\i0^+]\cup[k_p+\i0^-,k_s+\i0^-]$ that surround $[k_p,k_s]$, $C_l=[-k_s+\i0^+,-k_p+\i0^+]\cup[-k_s+\i0^-,-k_p+\i0^-]$ that surround $[-k_s,-k_p]$ and $\Ga$ denotes a circle with enough large radius. Since the function $\delta(\xi)$ clears does not have poles in the complex $\xi$-plane and we find that within the contour $C=\Ga\cup C_r\cup C_l$ the number of zeros is given by
\be \label{zero}
Z=\frac{1}{2\pi\i}\int_C \frac{d\delta}{d\xi}\frac{d\xi}{\delta(\xi)}
\ee
The counting of the number of zeros is carried out by mapping the $\xi$-plane on the $\eta$-plane through the relation $\eta:=\delta(\xi)$.
If $C_\eta$ is the mapping of $C$ in the $\eta$-plane, the integral (\ref{zero})
in the $\eta$-plane becomes
\be
Z=\frac{1}{2\pi\i}\int_{C_\eta} \frac{d\eta}{\eta}
\ee
The latter integral has a simple pole at $\eta=0$, and $Z$ is simply the number of times the image contour $C_\eta$ encircles the origin in the $\eta$-plane in the counter-clockwise direction. To determine the number of zeros in the $\xi$-plane we thus carefully trace the mapping of the contour $C$ into th $\eta$-plane.

Since $\delta(\xi)=\delta(-\xi)$ the images of $C_r$ and $C_l$ are the same, and one of them, say $C_r$, needs to be considered. We have $\delta(k_p)=(k_s^2-2k_p^2)^2$ and along $C_r$: $\delta(\xi)=(k_s^2-\xi^2)^2\mp\i4\xi^2\sqrt{k_s^2-\xi^2}\sqrt{\xi^2-k_p^2}$, and $\delta(k_s)=k_s^4$ where the minus sign applies above the cut, and the plus sign applies below the cut. Note that along $C_r$ we have $\Re(\delta(\xi))>0$ and the mapping into the $\eta$-plane do not surround the origin. For $|\xi|$ large, we find $\delta(\xi)=A\xi^2+O(1)$, thus the mapping of $\Ga$ encircles the origin twice. Then we obtain $Z=2$. This completes the proof.
\finproof

In order to overcome the ambiguity above, loss is assumed in the medium so that $k_{\alpha,\varepsilon}:=k_\alpha(1+\i\varepsilon)$.
When $\varepsilon>0$, the branch point of $\mu_{\alpha,\varepsilon}$ are $\pm k_{\alpha,\varepsilon}$ and the branch cut are denoted by the equation $\xi_1\xi_2=k_\alpha \varepsilon,-k_\alpha\leq \xi \leq k_\alpha$. In this case, the poles singularities are now located off the real axis and the Fouerier inverse transform becomes meaningful. In order to express lemma \ref{lem2.2} concisely, we define
\be
\Omega := \{\xi \in \mathbb{C} \ | \ k_p\varepsilon<\xi_1\xi_2<k_s\varepsilon \ , \  \ \xi_2>\xi_1\varepsilon\}
\ee
\begin{lem}\label{lem2.2}
	If the elastic medium has loss that $k_{\alpha,\varepsilon}:=k_\alpha(1+\i\varepsilon),0<\ep<1$ for $\alpha=p,s$, we assert that $\delta_\varepsilon(\xi)=0$ has only two roots in domain $\Omega^c \subset \mathbb{C}$ and exactly they are $\pm k_{R,\varepsilon}$.
\end{lem}

\begin{lem}\label{lem2.3}
Let $0<\ep<1$ and $z=R e^{\i\phi}$, $(1+\i\varepsilon)=r e^{\i\psi}$, where $0\leq\phi<2\pi$, $0<\psi<\pi/2$ and $R,r>0$. Then the equality
\be
 z^{1/2}=(1+\i\varepsilon)(\frac{z}{{1+\i\varepsilon}^2})^{1/2}
\ee
holds only when  $2\psi\leq\phi<2\pi$
\end{lem}
\debproof
Let $z_\ep=z/(1+\i\ep)^2:=r_\ep e^{\i\phi_\ep}$, then $\phi_\ep=\phi-2\psi$ when $2\psi\leq\phi<2\pi$.So it is easy to see that
\ben
z^{1/2}=\sqrt{R}e^{\i\phi/2}=\sqrt{R/r}\sqrt{r}e^{\i(\phi/2-\psi)+\i\psi}=(1+\i\ep)z_\ep^{1/2}
\een
Similarly, when $0\leq\phi<2\psi$, we have $\phi_\ep=\phi-2\psi+2\pi$ and then $z^{1/2}=-(1+\i\ep)z_\ep^{1/2}$. This completes the proof.
\finproof

\noindent {\bf Proof of lemma \ref{lem2.2}.}
The lemma now follow lemma\ref{lem2.1} and lemma\ref{lem2.3} easily. Denote by $\mu_\ep=(k^2(1+\i\ep)^2-\xi^2)^{1/2},k\in\R^+$ and write $\xi=\xi_1+\i\xi_2,\xi_1,\xi_2\in\R$ and $(1+\i\varepsilon)=r e^{\i\psi}$. It is easy to see that
\be
\mu_\ep^2 = k^2(1-\ep^2)-\xi_1^2+\xi_2^2+\i(2k^2\ep-2\xi_1\xi_2):=Re^{\i\Theta} := a_1+\i a_2
\ee
Let $\Delta:=\{ \xi | 2\psi\leq\Theta<2\pi \} $, then we have $ \mu_\ep = (k^2-\xi_\ep^2)^{1/2} (1+\i\ep)$ when $\xi \in\Delta$ and $ \mu_\ep = - (k^2-\xi_\ep^2)^{1/2} (1+\i\ep)$ when $\xi \notin\Delta$ by lemma\ref{lem2.3}. Now we divide the set $\Delta$ into three parts
\be
\hspace{-2cm}
\Delta = \{ \xi | a_1 \leq 0 \} \cup \{ \xi | a_2 \leq 0 \} \cup \{ \xi | a_1 >0,a_2 >0 \ \ \mbox{and} \ \ \tan\Theta \geq \tan(2\psi) \} \\ \nn
:= \Delta_1 \cup \Delta_2 \cup \Delta_3
\ee
Our goal now is to show where domain $\Delta$ occupies. A simple computation show that
\be
\Delta_1 = \{ \xi | \xi_1^2-\xi_2^2 \geq k^2(1-\ep^2) \}  \\
\Delta_2 = \{ \xi | \xi_1\xi_2 \geq k^2\ep \}
\ee
and
\be
\hspace{-2cm}
\Delta_3 = \{ \xi | \xi_1^2-\xi_2^2 \leq k^2(1-\ep^2), \xi_1\xi_2 \leq k^2\ep ,
\frac{k^2\ep-\xi_1\xi_2}{k^2(1-\ep^2)-(\xi_1^2-\xi_2^2)} \geq \frac{\ep}{1-\ep^2} \}
\ee
The domains denote by $\Delta_1,\Delta_2$ are obvious in complex plane. To locate $\Delta_3$ in complex plane, we divide $\Delta_3$ into tree parts $\Delta_3=\Delta_{31}\cup\Delta_{32}\cup\Delta_{33}$
where
\ben
\Delta_{31} &=& \{ \xi_1\xi_2 \leq 0, 0\leq\xi_1^2-\xi_2^2 \leq k^2(1-\ep^2) \} \\
\Delta_{32} &=& \{ 0 \leq \xi_1\xi_2 \leq k^2\ep, 0\leq\xi_1^2-\xi_2^2 \leq k^2(1-\ep^2), \frac{\xi_1\xi_2}{\xi_1^2-\xi_2^2} \leq \frac{\ep}{1-\ep^2} \} \\
            &=& \{ 0 \leq \xi_1\xi_2 \leq k^2\ep, 0\leq\xi_1^2-\xi_2^2 \leq k^2(1-\ep^2), \frac{\xi_2}{\xi_1} \leq \ep \} \\
\Delta_{33} &=& \{ \xi_1\xi_2 \leq 0, \xi_1^2-\xi_2^2 \leq 0 ,\frac{\xi_1\xi_2}{\xi_1^2-\xi_2^2} \geq \frac{\ep}{1-\ep^2} \} \\
            &=& \{ \xi_1\xi_2 \leq 0, \xi_1^2-\xi_2^2 \leq 0 ,-\frac{\xi_1}{\xi_2} \geq \ep \}
\een
Substituting $k_s,k_p$ into $\mu_\ep$ and let $\Delta_s,\Delta_p$ denote their corresponding areas, we have
\be
\C\bks\Omega = (\Delta_s \cap \Delta_p )\cup (\C\backslash(\Delta_s \cup \Delta_p))
\ee
Moreover, when $\xi\in\Omega$ it is easy to see $\delta_\ep(\xi)=\delta(\xi)(1-\i\ep)^4 $.
This complete the proof by lemma \ref{lem2.1}
\finproof

Let $\xi = \xi_1+\i\xi_2 \in \mathbb{C}$, $\xi_1 ,\xi_2 \in \mathbb{R}$, and the hyperbolic curve $\Gamma$ defined by the equation $\xi_1^2-\xi_2^2 = k_s^2$. Denote $\Gamma^+_r,\Gamma^-_r$ respectively the parts of right branch of $\Gamma$ in the upper-half complex plane and the lower-half complex plane. Similarily, we can define $\Gamma^-_l,\Gamma^-_l$.Now, we can define a new integral path in the complex plane
\be
NP=\left\{
\begin{array}{ll} \Gamma^+_l \cup \Gamma^+_r \cup [-k_s,k_s] \ \ \ \ \ \ \ \mbox{when} \ \ \ \ x_1-y_1>0 \\ \Gamma^-_l \cup \Gamma^-_r \cup [-k_s,k_s] \ \ \ \ \ \ \ \mbox{when} \ \ \ \ x_1-y_1<0	 \end{array} \right.
\ee

Thus, by using Cauchy integral theorem and lemma \ref{lem2.2}, we have
\be
N_\varepsilon(x,y)=\frac{1}{2\pi}\int^{+\infty}_{-\infty}\hat N_\varepsilon(\xi,x_2;y_2) e^{\i(x_1-y_1)\xi} d\xi
\\
=\frac{1}{2\pi}\int_{NP}\hat N_\varepsilon(\xi,x_2;y_2) e^{\i(x_1-y_1)\xi} d\xi\pm\i \mathit{Res}_{\xi=\pm k_R^\eps} N_\varepsilon(\xi,x_2;y_2) e^{\i(x_1-y_1)\xi}
\ee
As the perturbation $\varepsilon$ have nothing to do with the integration path $NP$, so we could take the limitation $\varepsilon\to0$. Thus, we have the representation of Green Tensor
\be
N(x,y)&=&\Phi(x,y)-\Phi(x,y')+\frac{1}{2\pi}\int_{NP}\hat N_c(\xi,x_2;y_2) e^{\i(x_1-y_1)\xi}d\xi\\ \nn
&& \pm \i  {\mathit{Res}}_{\xi=\pm\kappa_r}  \hat N_c(\xi,x_2;y_2) e^{\i(x_1-y_1)\xi}
\ee
where $\pm$ are corresponding $sgn(x_1-y_1)$.
Specially, $N(x,y)$ has a simple form when $x_2=0$ that
\be \label{pp12}
\hspace{-2cm}
N(x,y)&=&\frac{1}{2\pi}\int_{NP}\hat N(\xi,0;y) e^{\i(x_1-y_1)\xi}d\xi
 \pm \i  {\mathit{Res}}_{\xi=\pm\kappa_r}  \hat N(\xi,x_2;y) e^{\i(x_1-y_1)\xi}
\ee
where
\be \label{ngreen}
\hspace{-2cm}
\hat
        N(\xi,0;y_2)=\frac{\mathrm{i}}{\mu\delta(\xi)} \Bigg[ \Bigg(
		\begin{array}{cc}
			2\xi^2\mu_s & -2\xi\mu_s\mu_p\\
			-\xi\beta & \mu_p\beta
		\end{array} \Bigg)e^{\mathrm{i}\mu_p y_2}
		+ \Bigg(
		\begin{array}{cc}
			\mu_s\beta & \xi\beta \\
			2\xi\mu_s\mu_p & 2\xi^2\mu_p
		\end{array} \Bigg)e^{\mathrm{i}\mu_s y_2} \Bigg]
\ee
and let $N_r(x_1;y_1,y_2)$ denote the first part of $N$ and $N_s(x_1;y_1,y_2)$ denote the second part of $N$ in (\ref{pp12}).

It remains to study Dirichlet Green Tensor $D(x,y)$.
 We still use Fourier transform to derive the formula of Green Tensor in frequency domain. Then we can obtain $D(x,y)$ similar to $N(x,y)$. It follows an alternative representation for $D(x,y)$ 
\be
\hat D(\xi,x_2;y_2) = \hat \Phi(\xi,x_2;y_2)  -\hat \Phi(\xi,x_2;-y_2) + \hat M(\xi,x_2;y_2)
\ee
\be
\hat
{M}(\xi,x_2;y_2)&=& \frac{\mathrm{i}}{\omega^2 \gamma(\xi)} \Bigg\{ A(\xi)e^{\mathrm{i}\mu_s(x_2+y_2)}+B(\xi)e^{\mathrm{i}\mu_p(x_2+y_2)}\\ \nn
&&-A(\xi)e^{\mathrm{i}\mu_s x_2+\mu_p y_2}-B(\xi)e^{\mathrm{i}\mu_p x_2+\mu_s y_2}\Bigg\}
\ee
where
\ben
    &&{A(\xi)} =
	\left( \begin{array}{ll}
	\xi^2\mu_s & -\xi\mu_s\mu_p \\
	-\xi^3  & \xi^2\mu_p
	\end{array} \right)\ \ \ \ \ \
	{B(\xi)} =
	\left( \begin{array}{ll}
	\xi^2\mu_s & \xi^3 \\
	\xi\mu_s\mu_p  & \xi^2\mu_p
	\end{array} \right)
\een
and $\gamma(\xi)=\xi^2+\mu_s\mu_p$.
\begin{lem} \label{lem4.1}
	Let \emph{Lam\'{e}} constant $\lambda, \mu \in \C$ and $\Im(k_s)\geq0, \Im(k_p)\geq0$, then equation $\gamma(\xi) = 0$ has no root in complex plane.
\end{lem}
\debproof
Let $F(\xi)= \gamma(\xi)*(\xi^2-\mu_s\mu_p)$ and it is easy to see that the root of $\gamma(\xi) = 0$ is also of $F(\xi)=0$. A simple computation show that $F(\xi)=(k_s^2+k_p^2)\xi^2-k_p^2 k_s^2$. However, only when $\xi^2=k_p^2 k_s^2 / (K_s^2+k_p^2)$, $F(\xi)=0$ but $\gamma(\xi)=2 k_p^2 k_s^2 / (K_s^2+k_p^2)$.
 This completes the proof.
\finproof
Thus, we get the representation of Green Tensor by inverse Fourier transform
\be
D(x,y)&=&\Phi(x,y)-\Phi(x,y')+\frac{1}{2\pi}\int_{\R}\hat M(\xi,x_2;y_2) e^{\i(x_1-y_1)\xi}d\xi
\ee
Let $T_D(x,y)$ denote the traction of $D(x,y)$ in direction $e_2$ to variable $x$ that $T_D(x,y)e_i=T_x^{e_2}(D(x,y))e_i=T_x^{e_2}(D(x,y)e_i)$. Then we can get the representation of $T_D(x,y)$ by a trivial calculation.
\be
T_D(x,y)&=&T(x,y)-T(x,y')+\frac{1}{2\pi}\int_{\R}\hat T_M(\xi,x_2;y_2) e^{\i(x_1-y_1)\xi}d\xi
\ee
and
\be
\hat
T_M(\xi,x_2;y_2)&=& \frac{\mathrm{\mu}}{\omega^2 \gamma(\xi)} \Bigg\{ E(\xi)e^{\mathrm{i}\mu_s(x_2+y_2)}+F(\xi)e^{\mathrm{i}\mu_p(x_2+y_2)}\\ \nn
&&-E(\xi)e^{\mathrm{i}\mu_s x_2+\mu_p y_2}-F(\xi)e^{\mathrm{i}\mu_p x_2+\mu_s y_2}\Bigg\}
\ee
where
\ben
		&&{E(\xi)} =
		\left( \begin{array}{cc}
			-\xi^2\beta & \xi\mu_p\beta \\
			2\xi^3\mu_s & -2\xi^2\mu_s\mu_p
		\end{array} \right)\ \ \ \
		{F(\xi)} =
		\left( \begin{array}{cc}
			-2\xi^2\mu_s\mu_p & -2\xi^3\mu_p \\
			-\xi\mu_s\beta  & -\xi^2\beta
		\end{array} \right)
\een
Specially, $T_D(x,y)$ has a simple form when $x_2=0$ that
\be
\hat
    T_D(\xi,0;y_2)=\frac{1}{\gamma(\xi)}\Bigg[\Bigg(   \begin{array}{cc}
	\mu_s\mu_p & \xi\mu_p \\
	\xi\mu_s & \xi^2
	\end{array}		\Bigg)e^{\mathrm{i}\mu_s y_2}+\Bigg(   \begin{array}{cc}
	\xi^2 & -\xi\mu_p \\
	-\xi\mu_s & \mu_p\mu_s
	\end{array} \Bigg)e^{\mathrm{i}\mu_p y_2}
	\Bigg]	
\ee
and
\be
T_D(x_1,0;y_1,y_2)=\frac{1}{2\pi}\int_{\R}\hat T_D(\xi,0;y_2) e^{\i(x_1-y_1)\xi}d\xi
\ee

We need the following slight generalization of Van der Corput lemma for the oscillatory integral \cite[P.152]{grafakos}.
\begin{lem}\label{van}
	Let $-\infty<a<b<\infty$, and $u$ is a $C^k$ function $u$ in $(a,b)$. \\
 1. If $|u'(t)|\ge 1$ for $t\in (a,b)$ and $u'$ is monotone in (a,b), then for any $\phi(t)$ in $(a,b)$ with integrable derivatives
	\ben
	\left|\int^b_a e^{\i\lambda u(t)}\phi(t)dt\right|\le
	3\lambda^{-1}\left[|\phi(b)|+\int^b_a|\phi'(t)|dt\right].
	\een
 2. For all $k\geq2$, if $|u^{(k)}(t)|\ge 1$ for $t\in (a,b)$ , then for any $\phi(t)$ in $(a,b)$ with integrable derivatives
	\ben
	\left|\int^b_a e^{\i\lambda u(t)}\phi(t)dt\right|\le
	12k\lambda^{-1/k}\left[|\phi(b)|+\int^b_a|\phi'(t)|dt\right].
	\een
\end{lem}
\debproof
The assertion can be proved by extending the Van der Corptut lemma in \cite{grafakos}. Here we omit the details.
\finproof
We also have following more explicit estimation:
\begin{lem}\label{es_dgreen1}
Let $f(\xi,\mu_s,\mu_p)=g(\xi,\mu_s,\mu_p)/\gamma(\xi,\mu_s,\mu_p)$ where g(x,y,z) is a homogeneous quadratic polynomial with respect to x,y,z. Let $a,b>0$ and $\rho=\sqrt{a^2+b^2}$. Assume $a/\rho >(1+\kappa)/2$, $b/\rho < \kappa/2$, $\kappa=k_p/k_s$ and $k_s\rho >1$, then we have
\be \label{ap_estimation}
\Big|\int_\R f(\xi,\mu_s,\mu_p) e^{\i(\mu_s b +\xi a)}d\xi \Big| \leq C(\frac{k_s b}{\rho(k_s\rho)^{1/2}}+\frac{k_s a}{\rho(k_s\rho)^{3/2}})
\ee
and
\be
\Big|\int_\R f(\xi,\mu_s,\mu_p) e^{\i(\mu_p b +\xi a)} d\xi\Big| \leq C(\frac{k_s b}{\rho(k_s\rho)^{1/2}}+\frac{k_s a}{\rho(k_s\rho)^{3/2}})
\ee
where C is only dependent on $\kappa$.
\end{lem}
\debproof
Let I(a,b) denote the integral in the left side of inequality (\ref{ap_estimation}). To simplify the integral, the standard substitution $\xi=k_s\sin t$ is made, taking the $\xi$-plane to a strip $-\pi/2<\Re t <\pi/2$ in the t-plane, and the real axis in the $\xi$-plane onto the path L from $-\pi/2+\i\infty\rightarrow-\pi/2\rightarrow\pi/2\rightarrow\pi/2-\i\infty$ in the t-plane. The integral I(a,b) then becomes(Let a=$\rho \sin\phi$  and b=$\rho\cos\phi$, $0<\phi<\pi/4$)
\be
 k_s \int_L f(\sin t,\cos t,(\kappa^2-\sin^2 t)^{1/2})\cos t \ e^{\i k_s\rho(\cos (t-\phi))} dt
\ee
Taking the shift transformation of t and using cauchy integral theorem, we can obtain the representation of I(a,b):
\ben \hspace{-1.5cm}
k_s\int_L f(\sin (t+\phi),\cos (t+\phi),(\kappa^2-\sin^2 (t+\phi))^{1/2})\cos (t+\phi) e^{\i k_s\rho(\cos t)} dt \\\hspace{-2cm}
=k_s \cos \phi \int_L f(\sin (t+\phi),\cos (t+\phi),(\kappa^2-\sin^2 (t+\phi))^{1/2})\cos t \ e^{\i k_s\rho(\cos t)} dt \\\hspace{-2cm}
-k_s \sin \phi \int_L f(\sin (t+\phi),\cos (t+\phi),(\kappa^2-\sin^2 (t+\phi))^{1/2})\sin t \ e^{\i k_s\rho(\cos t)} dt \\\hspace{-2cm}
:=k_s (\cos\phi \ I_1+\sin\phi \ I_2)
\een
The lemma will be proved if we can show $|I_1|\leq C/(k_s\rho)^{1/2}$ and $|I_2|\leq C/(k_s\rho)^{3/2}$.

For $I_1$, we split the integral path L into $L_1=(-\pi/2,\pi/2)$ and $L_2=(-\pi/2+\i\infty,-\pi/2)\cup(\pi/2,\pi/2-\i\infty)$, then we have corresponding representation: $I_1=I_{11}+I_{12}$. A simple calculation gives that $f$ and $\pa f/\pa t$ are both integrable on path $L_1$. Further more, $\cos t>1/2$ for any $t\in(-\pi/4,\pi/4)$  while $|\sin t|>1/2$ for any $t\in (-\pi/2,-\pi/4)\cup(\pi/4,\pi/2)$. Then we have $|I_{11}|\leq C/(k_s\rho)^{1/2}$ following the lemma \ref{van}.

Moreover, because $f$ and $\pa f/\pa t$ has no singularity on $L_2$ and $\i\cos t \to -\infty$ as $t\to \infty$ along $L_2$, it is easy to see that $|I_{12}|\leq C/(k_s\rho)$ via integration by parts.

For $I_2$, using integration by parts on path $L$ first, we have
\be \hspace{-2cm}
I_2=\frac{1}{\i k_s\rho} \int_L f(\sin (t+\phi),\cos (t+\phi),(\kappa^2-\sin^2 (t+\phi))^{1/2}) d \ e^{\i(k_s\rho \cos t)} \\ \hspace{-1.5cm}
=-\frac{1}{\i k_s\rho} \int_{L_1 \cup L_2} \frac{\pa f(\sin (t+\phi),\cos (t+\phi),(\kappa^2-\sin^2 (t+\phi))^{1/2})}{\pa t
} \  e^{\i(k_s\rho \cos t)} dt \\ \hspace{-1.5cm}
=-\frac{1}{\i k_s\rho}(I_{21}+I_{22})
\ee
Then $|I_{22}|\leq C/(k_s\rho)$ can be proved by the same method used above. Following a tedious computation, we obtain a simple form of $\pa f/\pa t$:
\be
\frac{\pa f}{\pa t}&=&\frac{(\gamma\pa_t g  -g \pa_t \gamma)(\kappa^2-\sin^2 t)^{1/2}}{(\sin^2 t +\cos t (\kappa^2-\sin^2 t)^{1/2})^2}\frac{1}{(\kappa^2-\sin^2 t)^{1/2}} \\
&:=&\frac{h(\sin (t+\phi),\cos (t+\phi),(\kappa^2-\sin^2 (t+\phi))^{1/2})}{(\kappa^2-\sin^2 t)^{1/2}}
\ee
where $h$ and $\pa h/\pa t$ are integrable on path $L_1$. By the assumption above, there exist $0<\delta<\pi/4$ only dependent on $\kappa$ such that $|\sin(t+\phi)|>(1+\kappa)/2, |\cos(t+\phi)|<\kappa/2$ for any $t\in(-\delta,\delta)$ while $|\cos(t+\phi)|>(1+\kappa)/2, |\sin(t+\phi)|<\kappa/2$ for any $t\in(-\pi/2,-\pi/2+\delta)\cup(\pi/2-\delta,\pi/2)$. Let define $t_1,t_2\in \chi_1=(-\pi/2+\delta,-\delta)\cup(\delta,\pi/2-\delta)$ which satisfy $\kappa^2 = \sin^2 (t_i+\phi)$, $i=1,2$. Moreover, for any $0<\lambda_1<1$ and $1<\lambda_2<1/\kappa$, there exists $\sigma>0$, which satisfy that $\chi_2=(t_1-\sigma,t_1+\sigma)\cup(t_2-\sigma,t_2+\sigma)\subset\chi_1$ and is only dependent on $\lambda_1,\lambda_2,\kappa$, such that
\be \label{assume1}
\lambda_1\kappa<|\sin (t+\phi)|<\lambda_2\kappa.
\ee
for any $t\in\chi_2$. We are now in a position to estimate $I_{21}$. Similarly, we split the path $L_1$ into $\chi_2$ and $L_1\bks \chi_2$, then we have the corresponding representation: $I_{21}=I_{\chi_2}+I_{L_1\bks{\chi_2}}$.

For $I_{\chi_2}$, we only analysis the integral on $\chi_{21}=(t_1-\sigma,t_1+\sigma)$ denoted by $I^1_{\chi_2}$, the procedure of the another is same. Without loss of generality, we assume that $\sin (t_1-\sigma+\phi)<\kappa<\sin (t_1+\sigma+\phi)$. It is easy to see that $\sin (t+\phi)$ is monotonic increasing in $\chi_{21}$. Let $\sin (t+\phi) = \kappa \sin \theta$ and the implicit mapping from $\theta$ to $t$ is denoted by $t(\theta)$ while the inverse mapping by $\theta(t)$, taking the interval $\chi_{21}$ onto $L_\theta : \theta_1\rightarrow\pi/2\rightarrow\pi/2-\i\theta_2$ where $\sin(t_1-\sigma+\phi)=\kappa\sin \theta_1,\sin(t_1+\sigma+\phi)=\kappa\sin(\pi/2-\i\theta_2)$. By substituting $t(\theta)$ into $I^1_{\chi_2}$, we have
\be
I^1_{\chi_2}=\int_{L_\theta}\frac{ h(\kappa\sin\theta,(1-\kappa^2\sin^2\theta)^{1/2},\kappa\cos\theta)}{(1-\kappa^2\sin^2\theta)^{1/2}} \ e^{\i
k_s\rho(\cos(t(\theta)))} d\theta
\ee
Because of inequality \ref{assume1}, we assert that $h$ and $\pa h/\pa\theta$ are integrable on the path $L_\theta$. A simple computation show that
\ben
\frac{dt(\theta)}{d\theta}=\frac{\kappa\cos\theta}{\cos(t+\phi)} \ \
\frac{d^2 t(\theta)}{dt^2}=\frac{\kappa^2\cos^2\theta\sin(t+\phi)-\kappa\sin\theta\cos^2(t+\phi)}{\cos^3(t+\phi)}
\een
Then we can obtain
\ben
\frac{d\cos t}{d\theta}&=&\frac{-\kappa\sin t\cos\theta}{\cos(t+\phi)} \\
\frac{d^2\cos t}{d\theta^2}&=&\frac{d^2\cos t}{dt^2}(\frac{dt}{d\theta})^2+\frac{d\cos t}{dt}\frac{d^2t}{d\theta^2} \\
&=&\frac{-\kappa^2\cos^2\theta\cos t}{\cos^2(t+\phi)}+\frac{\kappa\sin\theta\cos^2(t+\phi)\sin t -\kappa^2\cos^2\theta\sin(t+\phi)\sin t}{\cos^3(t+\phi)} \\
&=&\frac{-\kappa^2\cos^2\theta\cos\phi+\kappa\sin\theta\cos^2(t+\phi)\sin t}{\cos^3(t+\phi)} \\
&=&\frac{(\sin^2(t+\phi)-\kappa^2)\cos\phi+\cos^2(t+\phi)\sin(t+\phi)\sin t}{\cos^3(t+\phi)}
\een
It is simple to see that $\theta=\pi/2$ is the only stationary point of $\cos(t(\theta))$ and we can obtain
\be
\Bigg|\frac{d^2\cos t}{d\theta^2}(\pi/2)\Bigg|=\frac{(1-\kappa^2)\kappa}{(1-\kappa^2)^{3/2}}|\sin t|>\frac{(1-\kappa^2)\kappa}{(1-\kappa^2)^{3/2}}\sin \delta
\ee
Therefore, we can choose appropriate $\lambda_1,\lambda_2$, only dependent on $\kappa$, such that $|\frac{d^2\cos t}{d\theta^2}|>\frac{(1-\kappa^2)\kappa}{(1-\kappa^2)^{3/2}}\sin \delta$ for any $\theta\in \theta(\chi_{21})$. Therefore, we can decompose $\theta(\chi_{21})$ into several intervals such that in each either $|\pa \cos(t(\theta))/\pa\theta|$ or $|\pa^2 \cos(t(\theta))/\pa\theta^2|$ has positive lower bound and $|\pa \cos(t(\theta))/\pa\theta|$ is monotonous. Since the amplitude function of integrand in $I^1_{\chi_2}$ and its derivative with respect to $\theta$ are both integrable on $L_\theta$, the estimation $|I^1_{\chi_2}|\leq C/(k_s\rho)^{1/2}$ can be obtained immediately by lemma \ref{van}.
Finally, an argument similar to the estimation of $I_{11}$ used shoes that $|I_{L_1\bks{\chi_2}}|\leq C/(k_s\rho)^{1/2}$. This completes the proof.

\finproof
Now, another more sophisticated estimation of $T_D(x_1,0;y_1,y_2)$ is a direct consequence of lemma \ref{es_dgreen1}.
\begin{lem}\label{es_dgreen2}
	For every $x\in\Gamma_0$, $y\in\R_+^2$ that $|x_1-y_1|/|x-y|>(1+\kappa)/2$, $y_2/|x-y|<\kappa/2$ and $k_s |x-y|>1$, we have
	\be
	|T_D(x,y)|\leq C(\frac{k_s y_2}{|x-y|}\frac{1}{(k_s|x-y|)^{1/2}}+\frac{k_s |x_1-y_1|}{|x-y|}\frac{1}{(k_s|x-y|)^{3/2}})
	\ee
	where C is only dependent on $\kappa$.
\end{lem}


\section{The forward scattering problem}

In this section we introduce the following stability estimate of the forward elastic scattering problem in the half space which can be proved by the limiting absorption principle by extending the classical argument in \cite{leis,wilcox1975,Yves1988}. Let the obstacle occupy a bounded Lipschitz domain $D\subset \R^2_+$.
\begin{thm} \label{eu1}
	Let $g \in H^{1/2}(\Ga_D)$, then the scattering problem of elastic equation in the half space
	\be
	\Delta_e u + \omega^2 u =0 \qquad\mbox{\rm in } \R^2_+\bks \bar{D}, \label{es1}\ \ \
	\\ u= g \ \ \ \ \mbox{\rm on } \Ga_D, \label{es2} \\
	\sigma(u)e_2=0 \ \ \ \ \mbox{\rm on} \Ga_0, \label{es3} \\
	u \ \mbox{satisfies the generalized radiation codition\cite{Guzina2006} such that} \nn \\\label{rc1}
	\lim_{r\to\infty}  \int_{S_r^+} (\sigma(N(x,y)e_i)\hat{r})\cdot u(x) - (N(x,y)e_i)\cdot (\sigma(u)\hat{r})ds(x)=0
	\ee
	where $S_r^+:=\{x\in \R^2_+ \ | \ \|x\|=r^2\}$, $\hat{r}=x/r$ and $y\in \R_+^2$. Then the problem (\ref{es1})-(\ref{rc1})
	admits a unique solution $u \in H^{1}_{\rm loc}(\R^2_+ \backslash \bar D)$. Moreover, for any bounded open set $\mathcal O\subset \R^2_+\bks\bar D$ there exists a constant $C>0$ such that
	\be \label{es4}
	\|u\|_{H^{1}(\mathcal O)}\le C\|g\|_{H^{-1/2}(\Ga_D)}
	\ee
\end{thm}
The existence of the solution can be proved by the method of limiting absorption principle. The argument is standard and we give several lemmas below, see e.g. \cite{leis} for the consideration for Helmholtz equation. For any $z=1+\i\varepsilon,\varepsilon>0$, $f\in H^{1}(\R^2_+)'$ with compact support in $B_R=\{x||x|^2<R^2,x\in\R^2_+\}\subsetneq\R_+^2$ where $B_R$ is a disk of radius R , we consider the problem
\be \label{eqz}
\Delta_e u_z +z\omega^2 u =-f \qquad\mbox{\rm in } \R^2_+ \\
\sigma(u_z)e_2=0 \ \ \ \ \mbox{\rm on} \ \ \ \  \Ga_0 \label{bdv}
\ee
By Lax-Milgrim lemma we know that (\ref{eqz}-\ref{bdv}) has a unique solution $u_z\in H^1(\R^2_+)$. For any domain $\mathcal D \subset \R^2_+$, we define the weighted space $L^{2,s}(\mathcal D),s \in \R$, by
\ben
L^{2,s}(\mathcal D)=\{v \in L^2_{\rm loc}(\mathcal D): (1+|x|^2)^{s/2}v \in L^2(\mathcal D) \}
\een
with the norm $\| v \|_{ L^{2,s}(\mathcal D)} = (\int_{\mathcal D}(1+|x|^2)^{s}|v|^2 dx )^{1/2}$. The weighted Sobolev space $H^{1,s}(\mathcal D),s \in \R$,
is defined as the set of functions in $L^{2,s}(\mathcal D)$ whose first derivative is also in $L^{2,s}(\mathcal D)$. The norm
$\| v \|_{ H^{1,s}(\mathcal D)} = (\| v \|^2_{ L^{2,s} (\mathcal D)} + \| \nabla v \|^2_{ L^{2,s}(\mathcal D)})^{1/2}$.

We need the following sligt generalization of Rellich Theorem:
\begin{lem}\label{rellich}
	Let $\Omega$ be an open Lipschitz domain, then the sobolev space $H^{1,-s}(\Omega)$ is compactly embeded in $L^{2,-s'}(\Omega)$ for every $s'>s>0$.
\end{lem}

\begin{lem}{\label{newton}}
	Let  $ f  \in L^2 (\R^2_+) $ with compact support in $B_R$. For any $z=1+\i\varepsilon$, $0<\varepsilon<1$, we have, for any $s>1/2$,
	$\|u_z\|_{H^{1,-s}(\R^2_+)}\le C\|f\|_{L^2(\R^2_+)}$ for some constant independent of $\varepsilon, u_z$, and $f$.
\end{lem}
\debproof
Let $R_z$ denote the map from $L^2_c(\R^2_+)$ to $H^{1,-s}(\R^2_+)$ such that $R_z(f)=u_z$ where $L^2_c(\R^2_+)$ is denoted by all $ f  \in L^2 (\R^2_+) $ with compact support in $B_R$, then it is easy to see that $R_z$ is a linear bounded operator. It follows from theorem 3.7 in \cite{Yves1988} that $R_z$ is a uniformly continuous operator continues valued function on $z=1+\i\varepsilon$, $0<\varepsilon<1$ with value in $B(L^2_c(\R^2_+),H^{1,-s}(\R^2_+))$. Then, we can obtain that $R_z$ is uniformly bounded in $B(L^2_c(\R^2_+),H^{1,-s}(\R^2_+))$. This complete the proof by the defintion of the operator norm.
\finproof

We next recall the following lemma which states the absence of positive eigenvalues for the linear elasticity system in half space \cite{sini2004}.
\begin{lem} \label{absen}
	Let $u\in L^2(\R^2_+ \backslash \bar D)$ such that $u$ satisfies (\ref{es1}) and (\ref{es3}), than we assert that $u=0$ in $\R^2_+ \backslash \bar D$
\end{lem}
\debproof
The asserting above can be proved by extending \cite[theorem 3.1]{sini2004}, here we omit the details.
\finproof

For any $0<\varepsilon<1$, we consider the problem
\be {\label{wg2}}
\Delta_e u_\varepsilon + (1+\i\varepsilon)\omega^2 u_\varepsilon=0 \qquad\mbox{\rm in } \R^2_+\bks \bar{D}\\
u_\varepsilon= g \ \ \ \ \mbox{\rm on } \Ga_D  \label{wg3}\\
\sigma(u_\eps)e_2=0 \ \ \ \ \mbox{\rm on} \Ga_0 \label{wg4}
\ee
We know that the above problem has a unique solution $u_{\varepsilon} \in H^1(\R^2_+ \backslash \bar D)$ by the Lax-Milgram Lemma. Thus, we have next lemma
\begin{lem}{\label{newton2}}
	Let  $ g  \in H^{1/2} (\Ga_D) $ . For any $0<\varepsilon<1$, we have, for any $s>1/2$,
	$\|u_{\eps}\|_{H^{1,-s}(\R^2_+ \backslash \bar D)} \leq C \|g\|_{H^{1/2}(\Ga_D)}$ for some constant independent of $\varepsilon, u_\eps$, and $g$.
\end{lem}
\debproof
Because $h=dist(D,\Ga_0)>0$, we can find three concentric circles $B_{R_1},B_{R_2},B_{R_3}$ such that $D\subsetneq B_{R_1}\subsetneq B_{R_2} \subsetneq B_{R_3} \subsetneq \R^2_+$. Let $\chi \in C_{0}^{\infty}(\R^2_+)$ be the cut-off function such that $0 \leq \chi \leq 1$, $\chi=0$ in $B_{R_1}$, and $\chi=1$ outside of $B_{R_2}$.
Let $v_\eps=\chi u_\eps$.
Then $v_\eps$ satisfies (\ref{eqz}) with
$z=1+\i\eps$ and $q=\sigma(u_\eps)\na\chi+(\lambda+\mu)(\na^2 \chi u_\eps+ \na u_\eps \na\chi)+\mu\Delta\chi u_\eps +\mu\div u_\eps\na\chi$, where $\na^2 \chi$ is the Hessian matrix of $\chi$. Clearly $q$ has compact support. By lemma \ref{newton} we can obtain
\be \label{q10}
\|v_\eps\|_{H^{1,-s}(\R^2_+)}\le C\|u_{\eps}\|_{H^1(B_{R_2}\backslash \bar{D})}
\ee
for some constant $C$ independent of $\eps>0$. Now let $\chi_1 \in C_{0}^{\infty}(\R^2_+)$
be the cut-off function with that  $0 \leq \chi_1 \leq 1$, $\chi_1=1$ in $B_{R_2}$, and $\chi_1=0$
outside of $B_{R_3}$. For $g\in H^{1/2}(\Ga_D)$, let $u_g \in H^{1}(\R^2_+ \backslash \bar{D})$ be the lifting function such that $  u_{g}=g \mbox{ on } \Ga_D$ and $\|u_{g}\|_{H^{1}(\R^2_+ \backslash \bar{D})}\le C\|g\|_{H^{1/2}(\Ga_D)}$. By testing \ref{wg2} with
$\chi_1^2 ( \overline{u_{\eps}-u_{g}} )$ and using the standard argument we have
\be \label{u1}
\|u_{\eps}\|_{H^{1}(B_{R_2} \backslash \bar{D})}\le C( \|u_{\eps}\|_{L^{2}(B_{R_3} \backslash \bar{D})} + \|g\|_{H^{1/2}(\Ga_D)} ).
\ee
A combination of (\ref{q10}) and the above estimate yields
\be \label{u2}
\|u_{\eps}\|_{H^{1,-s} ( \R^2_+ \backslash \bar{D})}\le C( \|u_{\eps}\|_{L^{2}(B_{R_3} \backslash \bar{D})} + \|g\|_{H^{1/2}(\Ga_D)} ).
\ee
Now we claim
\be \label{u3}
\|u_{\eps}\|_{L^2(B_{R_3} \backslash \bar D)} \leq C \|g\|_{H^{1/2}(\Ga_D)} ,
\ee
for any $g \in H^{1/2}(\Ga_D)$ and $\eps >0$. If it were false, there would exist sequences $\{g_m\} \subset H^{1/2}(\Ga_D)$ and $\{\eps_m\} \subset (0,1)$, and $\{u_{\eps_m}\}$ be the corresponding solution of (\ref{wg2})-(\ref{wg4}) such that
\be {\label{contradict}}
\|u_{\eps_m}\|_{L^2(B_{R_3} \backslash \bar D)} = 1 \ {\rm{ and }} \ \|g_m\|_{H^{-1/2}(\Ga_D)} \leq \frac{1}{m}.
\ee
Then $\|u_{\eps_m}\|_{H^{1,-s} ( \R^2_+ \backslash \bar{D})}\le C $, and thus there is a subsequence of $\{\eps_m\}$, which is
still denoted by $\{\eps_m\}$, such that $\eps_m \to \eps' \in [0,1]$, and a subsequence of $\{u_{\eps_m}\}$,
which is still denoted by $\{u_{\eps_m}\}$, such that it converges to some $u_{\eps'}$ in ${H^{1,-s'} ( \R^2_+ \backslash \bar{D})}$ by choosing $s'>s$. This is a consequence of Korn's inequality and Rellich theorem. So $u_{\eps'} \in H^{1,-s'}(\R^2_+ \backslash \bar D)$ satisfies (\ref{wg2}-\ref{wg4}) with $g=0$ and $\eps=\eps'$.

By the integral representation satistied by $u_{\eps_m}$, we know that for $y\in \R^2_+\backslash\bar B_{R_1}$ and $i=1,2$
\be \ \hspace{-2cm} \label{ge2}
u_{\eps'}(y)\cdot e^i=\int_{\pa B_{R_1}} (\sigma(N_{\eps'}(x,y)e_i)\nu)\cdot u_{\eps'}(x) - (N_{\eps'}(x,y)e_i)\cdot (\sigma(u_{\eps'})_{\eps'}\nu)ds(x)
\ee
If $\eps'>0$, we deduce  from (\ref{ge2}) that $u_{\eps'}$ decays exponentially and thus $u_{\eps'} \in H^{1}(\R^2_+\backslash \bar D) $, then $u_{\eps'} =0$ by the uniqueness of the solution in $H^{1}(\R^2_+ \backslash \bar D) $ with positive absorption.
If $\eps'=0$, by the \cite[theorem 5.2]{Yves1988}, we have $u_{\eps'}\in L^2(\R^2_+\bks\bar D)$. Then we conclude $u_{\eps'}=0$ by the lemma \ref{absen}
Therefore, in any case $u_{\epsilon'}=0$, which , however contradicts to \ref{contradict}. This complete the proof.
\finproof
Now we are in the position to prove the exsitence of Theorem \ref{eu1}.
\begin{lem} \label{ext}
	For any $s>1/2$, $u_\eps:(0,1)\to H^{1,-s}(\R^2_+ \bks \bar D)$ is a uniformly continuous operator valued function. Immediately, $u_{\eps}$ converges to some $u_0$ in $H^{1,-s}(\R^2_+ \bks \bar D)$ and $u_0$ is a solution of (\ref{es1}-\ref{es4}).
\end{lem}
\debproof
We also give a indirect prove here. Let $\delta_0>0$ and $\{\mu_n\}$ and $\{\nu_n\}$ be sequences in $ (0,1) $ such that
\be
|\mu_n-\nu_n|\le 1/n \qquad \mbox{and} \qquad \|u_{\mu_n}-u_{\nu_n}\|_{H^{1,-s}(\R^2_+ \bks \bar D)} \ge \delta_0
\ee
Thus there is a subsequence of $\{\mu_n\}$, which is still denoted by $\{\mu_n\}$, such that $\{\mu_n\}\to \epsilon\in[0,1]$ and also $\{\nu_n\}\to \epsilon$. Then using lemma \ref{newton2} and the procedure proving it, we get the $u_\epsilon,v_\epsilon \in H^{1,-s'} (\R^2_+ \bks \bar D)$, by choosing $s'>s$, such that
\ben
\|u_{\mu_n}-u_\epsilon\|_{H^{1,-s'}(\R^2_+ \bks \bar D)} \to 0 \\
\|u_{\nu_n}-v_\epsilon\|_{H^{1,-s'}(\R^2_+ \bks \bar D)} \to 0
\een
and $u_\epsilon=v_\epsilon$ by the same arguement in lemma \ref{newton2} which is contradict a contradiction. Thus we have proved $u_\eps$ is uniformly continuously for $\eps \in (0,1)$. Then it is easy to see $u_\eps$ has a limitation in ${H^{1,-s}(\R^2_+ \bks \bar D)} $ and the estimation of $u_0$ can be obtained by (\ref{u3}). This completes the proof.
\finproof
It is remain to prove the uniqueness in theorem \ref{eu1}. Actually, it can be obtained following the existence of solution with any $g\in H^{1/2}(\Ga_D)$.

{\it prove of Theorem \ref{eu1}}
By the linearity of the problem, it is sufficient to prove that any $u_0$  satisfies the system (\ref{es1}-\ref{es3}) with the corresponding homogeneous boundary-value vanishes identically in $\R^2_+\bks \bar D$. For any $y\in \R^2_+\bks \bar D$, there exists $U^s(x,y)$ sataifies (\ref{es1}-\ref{es3}) with $g(x)=-N(x,y)$ on $\Ga_D$ following the lemma \ref{ext} and we define $U(x,y)=N(x,y)+U^s(x,y)$. It is easy to see that $U(x,y)$ satifies the generalized radiation condition (\ref{rc1}). Thus by the integral representaion of $u_0$, we have
\ben
\lim_{r\to\infty}  \int_{S_r^+} (\sigma(U(x,y)e_i)\nu)\cdot u_0(x) - (U(x,y)e_i)\cdot (\sigma(u_0)\nu)ds(x)=0
\een
Finally, combining $U(x,y)=0,u_0(x)=0$ on $\Ga_D$ and the Green integral theorem we find that
\ben
u_0(y)e_i&=\int_{\R^2_+\bks\bar D} -(\Delta_e (N(x,y)e_i)+\omega^2 N(x,y)e_i)\cdot u_0(x) dx\\
&=\int_{\R^2_+\bks\bar D} \Delta u_0(x)\cdot (N(x,y)e_i)
-\Delta_e (N(x,y)e_i)\cdot u_0(x) \\
&=\int_{\Ga_D} (\sigma(U(x,y)e_i)\nu)\cdot u_0(x) - (U(x,y)e_i)\cdot (\sigma(u_0)\nu)ds(x)=0
\een
Then the desired unique exsitence follows with lemma \ref{ext}. This completes the proof of theorem \ref{eu1}.
\finproof


\section{Reverse time migration method}
In this section we introduce RTM method for inverse elastic scattering problems in the half space. Assume that there $N_s$ sources and $N_r$ receivers uniformly distributed on $\Gamma^d_0$, where $\Gamma^d_0=\{(x_1,x_2)^T\in\Gamma_0:x_1\in[-d,d]\},d>0$ is aperture. We denote by $\Omega$ the sampling domain in which the obstacle is sought. Let $h=dist(\Omega,\Gamma_0)$ be the distance of $\Omega$ to $\Gamma_0$. We assume the obstacle $D\subset\Omega$ and there exist constants $0<c_1<1,c_2>0,c_3>0$ such that
\be\label{om_bound}
|x_1|\leq c_1 d , \ \ |x_1-y_1|\leq c_2 h , \ \
|x_2|\leq c_3 h    \ \ \ \forall x,y \in \Omega
\ee

Our RTM algorithm consists of two steps \cite{Zhang08,Zhang2007}. The first step \cite{ela_reverse} is the back-propagation in which we back-propagate the complex conjugated data $\overline{u^s(x_r,x_s)}$ as the Dirichlet boundary condition into the domain. The second step is the cross-correlation in which we compute the imaginary part of the cross-correlation of the back-propagated field and the incoming wave which uses the source as the boundary codition on $\Gamma_0$.
\begin{alg}{\sc (Reverse time migration algorithm)}\\
Given the data $u_k^s(x_r,x_s)$, $k=1,2$ which is the measurement of the scattered field at $x_r$ when the source is emitted at $x_s$ in the  polarized direction $e_k$, $s=1,\dots, N_s$ and $r=1,\dots,N_r$. \\	
$1^\circ$ Back-propagation: For $s=1,\dots,N_s$ and k=1,2, compute the back-propagation field
\be
v_k(z,x_s)=\frac{|\Gamma_0^d|}{N_r}\sum^{N_r}_{r=1}(T^{e_2}_{x_r}D(x_r,z))^T\overline{u^s_k(x_r,x_s)}, \ \ \ \ \ \forall z\in\Omega
\ee
$2^\circ$ Cross-correlation: For $z\in\Om$, compute
\be\label{cor1}
I_d(z)=\Im\sum_{k=1}^{2}\left\{\frac{|\Gamma_0^d|}{N_s}\sum^{N_s}_{s=1}[(T^{e_2}_{x_s}D(x_s,z))^Te_k]\cdot v_k(z,x_s)\right\}.
\ee
\end{alg}

It is easy to that for $z\in\Om$
\be\hspace{-2.5cm}\label{cor2}
I_d(z)=\Im\sum_{k=1}^{2}\left\{\frac{|\Gamma_0^d|}{N_s}\frac{|\Gamma_0^d|}{N_r}\sum^{N_s}_{s=1}\sum^{N_r}_{r=1}[(T^{e_2}_{x_s}D(x_s,z))^Te_k]\cdot[(T^{e_2}_{x_r}D(x_r,z))^T\overline{u^s_k(x_r,x_s)}]\right\}
\ee
This formula is used in all our numerical experiments in section. By letting $N_s,N_r\to\infty$, we know that (\ref{cor2}) can be viewed as an approximation of the following continuous integral:
\be\hspace{-2.5cm}\label{cor3}
\hat{I}_d(z)=\Im\sum_{k=1}^{2}\int_{\Gamma_0^d}\int_{\Gamma_0^d}[(T^{e_2}_{x_s}D(x_s,z))^Te_k]\cdot[(T^{e_2}_{x_r}D(x_r,z))^T\overline{u^s_k(x_r,x_s)}]ds(x_r)ds(x_s)
\ee
where $z\in\Om$. We will study the resolution of the function $\hat{I}_d(z)$ in the section 5. To this end  we will first consider the resolution of the finite aperture point source function in the next function.

\section{The point spread function }
We start by introducing some notation.  For any bounded domain $U\subset \R^2$ with Lipschitz boundary $\Ga_U$ and the unit outer normal vector $\nu$, let
$\|u\|_{H^1(U)}=(\|\na \phi\|_{L^2(U)}^2+d_U^{-2}\|\phi\|_{L^2(U)}^2)^{1/2}$ be the weighted $H^1(U)$ norm
and
$\|v\|_{H^{1/2}(\Ga)}=(d_U^{-1}\|v\|_{L^2(\Ga)}^2+|v|_{\frac 12,\Ga}^2)^{1/2}$ be the weighted $H^{1/2}(\Ga)$ norm,
where $d_U$ is the diameter of $U$ and
\ben
|v|_{\frac 12,\Ga}=\left(\int_\Ga\int_\Ga\frac{|v(x)-v(y)|^2}{|x-y|^2}ds(x)ds(y)\right)^{1/2}.
\een
By scaling argument and trace theorem we know that there exists a constant $C>0$ independent of $d_D$ such that for any $\phi\in H^1(U)$ \cite[corollary 3.1]{RTMhalf_aco},
\be\label{q0}
\|\phi\|_{H^{1/2}(\Ga_U)}+\|\sigma(\phi)\cdot\nu\|_{H^{-1/2}(\Ga_U)}\le C\max_{x\in U}(|\phi(x)|+d_U|\na\phi(x)|)
%C_1\frac{|U|^{\frac 12}}{|\Ga|}\|v\|_{H^{1/2}(\Ga)}\le
%\inf_{{\phi|_{\Ga}=v,\,\phi\in H^1(U)}}\|\phi\|_{H^1(U)}\le C_2\frac{|U|^{\frac 12}}{d_U}\|v\|_{H^{1/2}(\Ga)}.
\ee

The point spread function measures the resolution for finding point source\cite{ammari2013mathematical}. In \cite{RTMhalf_aco}, the point spread function has been defined in the case of acoustic wave. We now define elastic point spread function $J(z,y)$, a $\mathbb{C}^{2\times2}$ matrix, which back-propagate the conjugated data $\overline{N(x,y)}$ as the Dirichlet boundary condition. Thus, for any $z,y \in \R_+^2$
\be
J(z,y)&=&\int_{\Gamma_0} \ (T_D(x,z))^T \overline{N(x,y)} ds(x) \\
&=&\int_\R \ (T_D(x_1,0;z_1,z_2))^T \overline{N(x_1,0;y_1,y_2)} dx_1
\ee
The estimate in (\ref{lem4.2}) show that the integral above exists.
Now, we define functions
\be \label{theta}
\hspace{-2cm}
\Theta(\xi;y_1,y_2)=\frac{1}{\gamma(\xi)}\Bigg[\Bigg(   \begin{array}{cc}
	\mu_s\mu_p & -\xi\mu_p \\
	-\xi\mu_s & \xi^2
\end{array}		\Bigg)e^{\mathrm{i}\mu_s y_2}+\Bigg(   \begin{array}{cc}
	\xi^2 & \xi\mu_p \\
	\xi\mu_s & \mu_p\mu_s
\end{array} \Bigg)e^{\mathrm{i}\mu_p y_2}
\Bigg]	e^{\i\xi y_1}
\ee
It is easy to see that, $\Theta=\overline{\hat T_D e^{-\i\xi -y_1}}$ when $\xi \in \R\bks [-k_s,k_s]$.

We split the spectral terms into components associated with pressure and shearing waves.
\ben
\hat{T_D}=\hat{T_D^p}+\hat{T_D^s} \ \ \
\hat{N}=\hat{N^p}+\hat{N^s}
\een
Thus, we define
\be\hspace{-1cm}
J^{\alpha\eta}(z,y)= \int_R \  ({T_D^\alpha}(x_1,0;z))^T \overline{{N^\eta}(x_1,0;y)} dx_1,
 \ \ \ \  \alpha=s,p \ \ \eta=s,p
 \ee
It's esay to see
\ben
J(z,y)=\sum_{\alpha=p,s}^{\eta=p,s} \ J^{\alpha\eta}(z,y)
\een
In order to analysis the PSF, loss is assumed in the medium that $k_{\alpha,\varepsilon}:=k_\alpha(1+\i\varepsilon)$. Then by Parseval identity and lemma \ref{lem2.2}, we carry out
\ben
J^{ss}(z,y)&=&\lim_{\varepsilon\to 0^+} \ \int_R \  ({T}^s_D (x_1,0;z_1,z_2))^T \overline{{N}^{s,\varepsilon} (x_1,0;y_1,y_2)} dx_1 \\
&=&\lim_{\varepsilon\to 0^+} \ \frac{1}{2\pi}\int_R \  (\hat{T}^s_D (\xi,0;z))^T \overline{\hat{N}^{s,\varepsilon} (\xi,0;y)} d\xi \\
&=& \frac{1}{2\pi}\int^{k_s}_{-k_s} \  (\hat{T}^s_D (\xi,0;z))^T \overline{\hat{N}^{s,\varepsilon} (\xi,0;y)} d\xi \\
&+&\lim_{\varepsilon\to 0^+} \ \frac{1}{2\pi}\int_{R\bks[-k_s,k_s]} \  (\hat{T}_D (\xi,0;z))^T \overline{\hat{N}^{s,\varepsilon} (\xi,0;y)} d\xi \\
&:=&F^{ss}(z,y)+R^{ss}(z,y)
\een
\ben
J^{pp}(z,y)&=&\lim_{\varepsilon\to 0^+} \ \int_R \  ({T}^p_D (x_1,0;z_1,z_2))^T \overline{{N}^{p,\varepsilon} (x_1,0;y_1,y_2)} dx_1 \\
&=&\lim_{\varepsilon\to 0^+} \ \frac{1}{2\pi}\int_R \  (\hat{T}^p_D (\xi,0;z))^T \overline{\hat{N}^{p,\varepsilon} (\xi,0;y)} d\xi \\
&=& \frac{1}{2\pi}\int^{k_p}_{-k_p} \  (\hat{T}^p_D (\xi,0;z))^T \overline{\hat{N}^{p,\varepsilon} (\xi,0;y)} d\xi \\
&+&\lim_{\varepsilon\to 0^+} \ \frac{1}{2\pi}\int_{R\bks[-k_p,k_p]} \  (\hat{T}^p_D (\xi,0;z))^T \overline{\hat{N}^{p,\varepsilon} (\xi,0;y)} d\xi \\
&:=&F^{pp}(z,y)+R^{pp}(z,y)
\een
\ben
J^{sp}(z,y)&=&\lim_{\varepsilon\to 0^+} \ \int_R \  ({T}^s_D (x_1,0;z_1,z_2))^T \overline{{N}^{p,\varepsilon} (x_1,0;y_1,y_2)} dx_1 \\
&=&\lim_{\varepsilon\to 0^+} \ \frac{1}{2\pi}\int_R \  (\hat{T}^s_D (\xi,0;z))^T \overline{\hat{N}^{p,\varepsilon} (\xi,0;y)} d\xi \\
&=& \frac{1}{2\pi}\int^{k_p}_{-k_p} \  (\hat{T}^s_D (\xi,0;z))^T \overline{\hat{N}^{p,\varepsilon} (\xi,0;y)} d\xi \\
&+&\lim_{\varepsilon\to 0^+} \ \frac{1}{2\pi}\int_{R\bks[-k_p,k_p]} \  (\hat{T}^s_D (\xi,0;z))^T \overline{\hat{N}^{p,\varepsilon} (\xi,0;y)} d\xi \\
&:=&F^{sp}(z,y)+R^{sp}(z,y)
\een
\ben
J^{ps}(z,y)&=&\lim_{\varepsilon\to 0^+} \ \int_R \  ({T}^p_D (x_1,0;z_1,z_2))^T \overline{{N}^{s,\varepsilon} (x_1,0;y_1,y_2)} dx_1 \\
&=&\lim_{\varepsilon\to 0^+} \ \frac{1}{2\pi}\int_R \  (\hat{T}^p_D (\xi,0;z))^T \overline{\hat{N}^{s,\varepsilon} (\xi,0;y)} d\xi \\
&=& \frac{1}{2\pi}\int^{k_p}_{-k_p} \  (\hat{T}^p_D (\xi,0;z))^T \overline{\hat{N}^{s,\varepsilon} (\xi,0;y)} d\xi \\
&+&\lim_{\varepsilon\to 0^+} \ \frac{1}{2\pi}\int_{R\bks[-k_p,k_p]} \  (\hat{T}^p_D (\xi,0;z))^T \overline{\hat{N}^{s,\varepsilon} (\xi,0;y)} d\xi \\
&:=&F^{ps}(z,y)+R^{ps}(z,y)
\een
and using Cauchy integral theorem, we get
\ben
\overline{R^{ss}(y,z)}&=&\lim_{\varepsilon\to 0^+} \ \frac{1}{2\pi}\int_{R\bks[-k_s,k_s]} \  \overline{(\hat{T}^s_D (\xi,0;z))^T} \hat{N}^{s,\varepsilon} (\xi,0;y) d\xi \\
&=&\lim_{\varepsilon\to 0^+} \ \frac{1}{2\pi}\int_{R\bks[-k_s,k_s]} \  (\Theta^s (\xi;z))^T \hat{N}^{s,\varepsilon} (\xi,0;y) d\xi  \\
&=& \ \frac{1}{2\pi}\int_{\Gamma^\pm_l \cup \Gamma^\pm_r} \  (\Theta^s (\xi;z))^T \hat{N}^{s} (\xi,0;y) d\xi + Residue Part \\
&:=&{\MyRoman{1}}^{ss}(z,y)+{\MyRoman{2}}^{ss}(z,y)
\een
\ben
\overline{R^{pp}(y,z)}&=&\lim_{\varepsilon\to 0^+} \ \frac{1}{2\pi}\int_{R\bks[-k_p,k_p]} \  \overline{(\hat{T}^p_D (\xi,0;z))^T} \hat{N}^{p,\varepsilon} (\xi,0;y) d\xi \\
&=&\lim_{\varepsilon\to 0^+} \ \frac{1}{2\pi}\int_{R\bks[-k_p,k_p]} \  (\Theta^p (\xi;z))^T \hat{N}^{p,\varepsilon} (\xi,0;y) d\xi  \\
&=& \ \frac{1}{2\pi}\int_{\Gamma^\pm_l \cup \Gamma^\pm_r} \  (\Theta^p (\xi;z))^T \hat{N}^{p} (\xi,0;y) d\xi \\
&+& \frac{1}{2\pi}\int_{(-k_s,-k_p)\cup(k_p,k_s)} \  \overline{(T^p (\xi;z))^T} \hat{N}^{p} (\xi,0;y) d\xi+Residue Part \\
&:=&{\MyRoman{1}}^{pp}(z,y)+{\MyRoman{2}}^{pp}(z,y)+{\MyRoman{3}}^{pp}(z,y)
\een
\ben
\overline{R^{sp}(y,z)}&=&\lim_{\varepsilon\to 0^+} \ \frac{1}{2\pi}\int_{R\bks[-k_p,k_p]} \  \overline{(\hat{T}^s_D (\xi,0;z))^T} \hat{N}^{p,\varepsilon} (\xi,0;y) d\xi \\
&=&\lim_{\varepsilon\to 0^+} \ \frac{1}{2\pi}\int_{R\bks[-k_p,k_p]} \  (\Theta^s (\xi;z))^T \hat{N}^{p,\varepsilon} (\xi,0;y) d\xi  \\
&=& \ \frac{1}{2\pi}\int_{\Gamma^\pm_l \cup \Gamma^\pm_r} \  (\Theta^s (\xi;z))^T \hat{N}^{p} (\xi,0;y) d\xi \\
&+& \frac{1}{2\pi}\int_{(-k_s,-k_p)\cup(k_p,k_s)} \  \overline{(T^s (\xi;z))^T} \hat{N}^{p} (\xi,0;y) d\xi+Residue Part \\
&:=&{\MyRoman{1}}^{sp}(z,y)+{\MyRoman{2}}^{sp}(z,y)+{\MyRoman{3}}^{sp}(z,y)
\een
\ben
\overline{R^{ps}(y,z)}&=&\lim_{\varepsilon\to 0^+} \ \frac{1}{2\pi}\int_{R\bks[-k_p,k_p]} \  \overline{(\hat{T}^p_D (\xi,0;z))^T} \hat{N}^{s,\varepsilon} (\xi,0;y) d\xi \\
&=&\lim_{\varepsilon\to 0^+} \ \frac{1}{2\pi}\int_{R\bks[-k_p,k_p]} \  (\Theta^p (\xi;z))^T \hat{N}^{s,\varepsilon} (\xi,0;y) d\xi  \\
&=& \ \frac{1}{2\pi}\int_{\Gamma^\pm_l \cup \Gamma^\pm_r} \  (\Theta^p (\xi;z))^T \hat{N}^{s} (\xi,0;y) d\xi \\
&+& \frac{1}{2\pi}\int_{(-k_s,-k_p)\cup(k_p,k_s)} \  \overline{(T^p (\xi;z))^T} \hat{N}^{s} (\xi,0;y) d\xi+Residue Part \\
&:=&{\MyRoman{1}}^{ps}(z,y)+{\MyRoman{2}}^{ps}(z,y)+{\MyRoman{3}}^{ps}(z,y)
\een
where $\pm$ are corresponding $sgn(z_1-y_1)$. In the sequel, $A^{ij}$ denotes the $(i,j)$ element of a $2\times2$ matrix.
\begin{thm}
For any $z,y\in\Om$, J(z,y)=F(z,y)+R(z,y), where
\be
F(z,y)=F_{ss}(z,y)+F_{pp}(z,y) \\
R(z,y)=R^{ss}(z,y)+R^{pp}(z,y)+J^{sp}(z,y)+J^{ps}(z,y) 
\ee
Moreover, 
\be
|R^{ij}(z,y)|+k_s^{-1}|\na_y R^{ij}(z,y)|\leq \frac{C}{\mu}(\frac{1}{(k_s h)^{\frac{1}{2n^*}}}+e^{-\sqrt{k_R^2-k_s^2}h})
\ee
 uniformly for $z,y\in\Om$. Here the constant C may dependent on $k_s d_D$ and $\kappa:=k_p/k_s$, but is independent of k, h, $d_D$.
\end{thm}
\begin{lem} \label{r_estimate1}
	For any $z,y\in \R^2_+$,
	\be\label{re1}
	|{\MyRoman{1}}^{\alpha\beta}_{ij}(x,y)|\le\frac{C}{\mu }\sum_{j=1}^{4}(k_s(y_2+z_2))^{-j}, \ \alpha,\beta=s,p
	\ee
	where $C$ is only dependent on $\kappa:=k_p/k_s$.
\end{lem}
\debproof
Substituting (\ref{theta}) and (\ref{ngreen}) into ${\MyRoman{1}}^{ss}$, we have
\ben
\hspace{-2cm}
{\MyRoman{1}}^{ss}(z,y)=\frac{1}{2\pi}\int_{\Gamma^\pm_l \cup \Gamma^\pm_r} \frac{\i(k_s^2-4\xi^2)}{\mu\gamma(\xi)\delta(\xi)}
\Bigg(
  \begin{array}{cc}
	\mu_s^2\mu_p & \xi\mu_s\mu_p \\
	-\xi\mu_s\mu_p & -\xi^2\mu_p
\end{array}		\Bigg)e^{\mathrm{i}\mu_s (z_2+y_2) +\i\xi(z_1-y_1)} \\
=A_l+A_r
\een
where $A_r, A_l$ are respected the integrantion on the $\Gamma^+_r,\Gamma^+_l$.
Now, we turn to estimation of $\MyRoman{1}^{ss}$.
 The integration path $\Gamma_r^+$ can be parameterized by $\xi:=k_s q(t)=k_s \sqrt{t^2+1} + \mathrm{i} k_s t$, with $0<t<+\infty$. We define $\gamma_p(t):=(\kappa^2-q(t)^2)^{1/2}$, $\gamma_s(t)=(1-q(t)^2)^{1/2}$, and $\tau(t):=1-2t^2$. It is well know that $\mu_\alpha=k_s\gamma_\alpha(t)$, $ \beta(\xi)=k_s^2\tau(t)$, $\gamma(\xi)=k_s^2(q(t)^2+\gamma_p(t)\gamma_s(t))$ and $\delta(\xi)=k_s^4(\tau(t)^2+4q(t)^2\gamma_p(t)\gamma_s(t))$ when $\xi$ on $\Gamma_r^+$. Now, substituting the parameterized representation of $\xi$ on $\Gamma^+_r$, we obtain
 \be
 A_r^{11}=\int_{0}^{+\infty} \frac{A(t)}{\mu}e^{\i k_s[\gamma_s(t)(z_2+y_2)+q(t)(z_1-y_1)]} dt
 \ee
 where $A(t)=\frac{\i(1-4q(t)^2)\gamma_s(t)^2\gamma_p(t)(\i+t/\sqrt{1+t^2})}{2\pi (q(t)^2+\gamma_p(t)\gamma_s(t))(\tau(t)^2+4q(t)^2\gamma_p(t)\gamma_s(t))}$.

 A simple computation show that  $A(t)=O(t^3), \  t\to+\infty$. It is obvious that there exit $T,C>0$ which only dependent on $\kappa$
 \be
 |A(t)|\leq Ct^3
 \ee
 when $t>T$. By the convention in (\ref{q1}), it is easy to see
 \be
 \gamma_s(t)=(1+t^2)^{1/4}t^{1/2}(-1+\i)
 \ee
 Cause $\delta(\xi)$ and $\gamma(\xi)$ have no zero point on $\Gamma^+_r$, we have
 \ben
 \hspace{-2.2cm}
 |A_r|\le\frac{1}{\mu}\int_{0}^{+\infty} |A(t)|e^{-ks \Im\gamma_s(t)(z_2+y_2)} dt \\
 \hspace{-1.3cm}
 \le \frac{1}{\mu}\int_{0}^{T} \max_{[0,T]}A(t) e^{-ks \Im\gamma_s(t)(z_2+y_2)} dt + \frac{C}{\mu}\int_T^{+\infty} t^3 e^{-ks \Im\gamma_s(t)(z_2+y_2)} dt \\
 \hspace{-1.3cm}
 =\frac{\max_{[0,T]}A(t)}{\mu}\int_{0}^{T}  e^{-ks (1+t^2)^{1/4}t^{1/2}(z_2+y_2)} dt + \frac{C}{\mu}\int_T^{+\infty} t^3 e^{-ks (1+t^2)^{1/4}t^{1/2}(z_2+y_2)} dt\\
 \hspace{-1.3cm}
 \le\frac{\max_{[0,T]}A(t)}{\mu}\int_{0}^{T}  e^{-ks t(z_2+y_2)} dt + \frac{C}{\mu}\int_T^{+\infty} t^3 e^{-ks t(z_2+y_2)} dt\\
 \hspace{-1.3cm}
 \le \frac{C}{\mu } \sum_{j=1}^{4}(k_s(y_2+z_2))^{-j}
 \een
where we use integration by parts for last inequatily. The estimate of $A_l$ and the case of $y_1-z_1<0$ can be proved similarly. Thus, we obtain (\ref{re1}) when $i=j=1,\alpha=\beta=s$. The estimation of other term ${\MyRoman{1}}_{\alpha\beta}^{ij}(z,y)$ can be proved similarly via integration by parts argument and the fact that $
\Im \gamma_s(t) \le \Im \gamma_p(t), \ t>0 $. This completes the proof.
\finproof
\begin{lem} \label{r_estimate2}
	For any $z,y\in \R^2_+$,
	\be\label{re2}
	|{\MyRoman{2}}^{pp}_{ij}(x,y)|\le\frac{C}{\mu k_s(y_2+z_2)} \\
	|{\MyRoman{2}}^{sp}_{ij}(x,y)|\le\frac{C}{\mu k_s y_2} \\
	|{\MyRoman{2}}^{ps}_{ij}(x,y)|\le\frac{C}{\mu k_s z_2}
	\ee
	where $C$ is only dependent on $\kappa:=k_p/k_s$.
\end{lem}
\debproof
Substituting (\ref{theta}) and (\ref{ngreen}) into ${\MyRoman{2}}^{pp}$, we have
\ben
\hspace{-2cm}
{\MyRoman{2}}^{pp}(z,y)=\frac{1}{2\pi}\int_{(-k_s,-k_p)\cup(k_p,k_s)} \frac{£­\i k_s^2}{\mu\overline{\gamma(\xi)}\delta(\xi)}
\Bigg(
\begin{array}{cc}
	\xi^2\mu_s & -\xi\mu_s\mu_p \\
	\xi\mu_s\mu_p & -\mu_s\mu_p^2
\end{array}		\Bigg)e^{\mathrm{i}\mu_p (z_2+y_2) +\i\xi(z_1-y_1)}
\een
let $\xi=k_s t$, we have
\ben
\hspace{-3cm}
|{\MyRoman{2}}^{pp}_{11}|\leq \int_{\kappa}^{1}\frac{\sqrt{(1-t^2)}t^2}{\pi\mu|t^2-\i\sqrt{(t^2-\kappa^2)}\sqrt{(1-t^2)}|(1-2t^2)^2+\i4t^2\sqrt{(t^2-\kappa^2)}\sqrt{(1-t^2)}|}e^{-k_s\sqrt{t^2-\kappa^2}(z_2+y_2)}dt \\
\leq \frac{C}{\mu}\int_{0}^{1-\kappa}e^{t(z_2+y_2)}dt\leq
\frac{C}{\mu k_s(y_2+z_2)}
\een
where we use the fact that $\gamma(\xi),\delta(\xi)$ have no roots on interval $[k_p,k_s]$, then we can get supremum of amplitude function. The method of estimating other terms are actually same, here we omit detials. This completes the proof.
\finproof
\begin{lem} \label{r_estimate3}
	For any $z,y\in \R^2_+$,
	\be\label{re3}
	|{\MyRoman{2}}^{ss}_{ij}(x,y)|\le\frac{C}{\mu}e^{-\sqrt{k_R^2-k_s^2}(y_2+z_2)} \\
	|{\MyRoman{3}}^{pp}_{ij}(x,y)|\le\frac{C}{\mu}e^{-\sqrt{k_R^2-k_p^2}(y_2+z_2)}\\
	|{\MyRoman{3}}^{sp}_{ij}(x,y)|\le\frac{C}{\mu}e^{-\sqrt{k_R^2-k_s^2}z_2-\sqrt{k_R^2-k_p^2}y_2}\\
	|{\MyRoman{3}}^{ps}_{ij}(x,y)|\le\frac{C}{\mu}e^{-\sqrt{k_R^2-k_p^2}z_2-\sqrt{k_R^2-k_s^2}y_2}
	\ee
	where $C$ is only dependent on $\kappa:=k_p/k_s$.
\end{lem}
\debproof
When $z_1-y_1>0$, we have
\ben
{\MyRoman{2}}^{ss}_{11}&=&-\frac{1}{\mu} Res_{\xi=k_R} \frac{(k_s^2-4\xi^2)\mu_s^2\mu_p}{\gamma(\xi)\delta(\xi)}e^{\i\mu_s (z_2+y_2) +\i\xi(z_1-y_1)} \\
&=&- \frac{(k_s^2-4\xi^2)\mu_s^2\mu_p}{\mu(\gamma(\xi)\delta(\xi))'}e^{\i\mu_s (z_2+y_2) +\i\xi(z_1-y_1)} |_{\xi=k_R}
\een
Eliminating $k_s$ in fraction, we can obtain estimation (\ref{re3}). The other terms can be estimated similarly. This completes the proof.
\finproof
Now, it turn to estimate $F^{sp}(z,y)$ and $F^{ps}(z,y)$.
\begin{lem}
	For $0<\kappa<1$, let $F(\lambda)=\int_{0}^{\kappa}f(t)e^{\i\lambda(\sqrt{1-t^2}-\tau\sqrt{\kappa^2-t^2}+\alpha t)}dt$, where $\tau\geq c_0>0$ and $\alpha\in\R$, then we have
	\ben
	|F(\lambda)|\leq C(\kappa) \lambda^{-\frac{1}{2N_*}} \Big[|f(\kappa)|+\int_{0}^{\kappa}|f'(t)|dt\Big]
	\een
	where $N_*=\min\{N|\kappa^{2N-1}<c_0,N\in \Z_+ \}$.
\end{lem}
\debproof
Put $\phi(t)=-\sqrt{1-t^2}$ and $\psi(t,\tau)=\tau\phi(t/\kappa)-\phi(t)+\alpha t$. For easy of notations, we denote the $n$-th partial derivative of $g(t)$ with respect to $t$ by $g^{(n)}(t)$. Then, it is to see that, for $n>1$
\ben
\psi^{(n)}(t,\tau)=\frac{\tau}{\kappa^{n-1}}\phi^{(n)}(\frac{t}{\kappa})-\phi^{(n)}(t)
\een
A standard computation show that
\ben
\phi^{(1)}(t)=\frac{t}{\sqrt{1-t^2}}  \\
\phi^{(2)}(t)=\frac{1}{(1-t^2)^{3/2}}\\
\phi^{(3)}(t)=\frac{3t}{(1-t^2)^{5/2}}
\een
Moreover, for $n\geq3$, we have
\be
\phi^{(n)}(t)=\frac{p_n(t)}{(1-t^2)^{n-1/2}}
\ee
where $p_n=\sum_{0}^{n-2}a^n_{k}t^k$ is a $(n-2)$-th polynomial such that its  coefficients satisfy the following recursion formula:
\ben
a^{n+1}_{n-1}=(n+1)a^n_{n-2}, \ \ \ a^{n+1}_{n-2}=(n+2)a^n_{n-3} \\
a^{n+1}_{k}=(k+1)a^n_{k+1}+(2n-k)a^n_{k-1} \ \ \ \mbox{for} \ 1\leq k\leq n-3 \\
a^{n+1}_{0}=a^n_{1}
\een
Since the polynmial coefficients are all positive, it is obvious that for $n\geq 1$, $\phi^{(n)}(t)$ is a monotone increasing positive function. Using the recursion formula, it follows that
\be \label{value_0}
\phi^{(n)}(0)=\left\{ \begin{array}{ll}
	\ \ \ \ \ \ 	0  \ \ \ \ \ \ \ \ \ \ \  \ \ \ \ \ \  \mbox{n is odd},\\
	(n-1)!!(n-3)!! \ \ \mbox{n is even}.
\end{array} \right.
\ee
where $(2k-1)!!$ is double factorial and $n>3$. We are now in the position to proof the inequality. Since $0<\kappa<1$, obersev that 
\ben
\psi^{(2N_*+1)}(t,\tau)\geq \frac{\tau}{\kappa^{2N_*}}\phi^{(2N_*+1)}(t)-\phi^{(2N_*+1)}(t)>0
\een
Therefore, $\psi^{(2N_*)}(t,\tau)$ is monotone increasing in $[0,\kappa)$. By (\ref{value_0}), we get
\be\hspace{-1.5cm}
\psi^{(2N_*)}(t,\tau)\geq\psi^{(2N_*)}(0,\tau)\geq\psi^{(2N_*)}(0,c_0)=C(2N_*)(\frac{c_0}{\kappa^{2N_*-1}}-1)>0
\ee
The lemma is now a direct consequence of lemma (\ref{van}).
\finproof
The parameterization of hyperbolic curve passing $(\pm1,0)$ is:
\ben
\xi_1=\pm\sqrt{t^2+1} \ \ \ \ \xi_2= t
\een
where $t\in\R$. Substituting $\xi=\xi_1+\i\xi_2$ into $\mu(\xi):=(1-\xi^2)^{1/2}$ and $\mu_\kappa(\xi):=(\kappa^2-\xi^2)^{1/2}$, we get
\ben
\Im\mu(\xi)&=&\Im(1-(\xi_1^2-\xi_2^2+\i2\xi_1\xi_2))^{1/2}\\&=&\Im(-2t\sqrt{t^2+1}\i)^{1/2}=t^{1/2}(t^2+1)^{1/4}
\een
\ben
\Im\mu_\kappa(\xi)&=&\Im(\kappa^2-(\xi_1^2-\xi_2^2+\i2\xi_1\xi_2))^{1/2}\\&=&\Im(\kappa^2-1-2t\sqrt{t^2+1}\i)^{1/2}\\ &=&\sqrt{\frac{\sqrt{(1-\kappa^2)^2+4t(t^2+1)}+1-\kappa^2}{2}}\\
&\geq&t^{1/2}(t^2+1)^{1/4}
\een
where we only consider the branch, denoted by $\Gamma^+$, in the first quadrant here. For $a>0,b>0$, we have
\ben
|e^{\i\xi a+\i\mu(\xi)b+\i\mu_\kappa(\xi)c}|\leq e^{-ta-t^{1/2}(t^2+1)^{1/4}b-t^{1/2}(t^2+1)^{1/4}c}\leq e^{-t(b+c)} 
\een 
\begin{lem}
	For $\xi\in\Gamma_0$, let $f(\xi)$ is a complex valued function in $L^1(\Gamma^+)$ such that $|f(\xi)|\leq C(1+\xi^k)$, $k\in \Z_+$. Then we have
	\ben
	|I(a,b,c):=\int_{\Gamma^+}f(\xi)  \ e^{\i\xi a+\i\mu(\xi)b+\i\mu_\kappa(\xi)c} \ d\xi| \\
	\leq C(\frac{1}{b+c}+\frac{1}{(b+c)^k})
	\een
\end{lem}
\debproof
\ben
\frac{d\xi(t)}{dt}=\frac{t}{\sqrt{t^2+1}}+\i
\een
Substituting $\xi(t)$ into $I(a,b,c)$, we hvae
\ben
|I(a,b,c)|&=&\Big|\int_{0}^{\infty}|f(\xi(t))\frac{d\xi(t)}{dt}e^{\i\xi(t) a+\i\mu(\xi(t))b+\i\mu_\kappa(\xi(t))c}dt \Big| \\
&\leq&C\int_{0}^{\infty}(1+t^k) e^{-t(b+c)} dt\\
&\leq& C(\frac{1}{b+c}+\frac{1}{(b+c)^k})
\een
\finproof
\begin{lem}
	Let $f(\xi)$ is a bounded complex valued function in $L^1((\kappa,1))$. Then we have
	\ben
	|I(a,b):=\int_{\kappa}^{1}|f(\xi)e^{\i\xi a+\i\mu_\kappa(\xi)b}d\xi|\\
	\leq C\frac{1}{b}
	\een
\end{lem}
\debproof
It is simple to see that
\ben
|I(a,b)|&\leq& C \int_{\kappa}^{1}e^{-b\sqrt{\xi^2-\kappa^2}}d\xi \\
&\leq& C\int_{0}^{\sqrt{1-\kappa^2}}\frac{t}{\sqrt{t^2+\kappa^2}}e^{-bt}dt \\
&\leq& C\frac{1}{b}
\een
\finproof


To complete the analysis of the point spread function, Let $F(z,y)=F_{ss}(z,y)+F_{pp}(z,y)$, where
\ben
\hspace{-2cm}
F^{pp}(z,y)=-\frac{1}{2\pi}\int_{(-k_p,-k_p)} \frac{\i k_s^2\mu_s}{\mu\gamma(\xi)\delta(\xi)}
\Bigg(
\begin{array}{cc}
	\xi^2 & -\xi\mu_p \\
	-\xi\mu_p & \mu_p^2
\end{array}		\Bigg)e^{\mathrm{i}\mu_p (z_2-y_2) +\i\xi(y_1-z_1)} \\
\hspace{-2cm}
F^{ss}(z,y)=-\frac{1}{2\pi}\int_{(-k_p,-k_p)} \frac{\i k_s^2\mu_p}{\mu\gamma(\xi)\delta(\xi)}
\Bigg(
\begin{array}{cc}
	\mu_s^2 & \xi\mu_s \\
	\xi\mu_s & \xi^2
\end{array}		\Bigg)e^{\mathrm{i}\mu_p (z_2-y_2) +\i\xi(y_1-z_1)} \\
-\frac{1}{2\pi}\int_{(-k_s,k_s)\bks(-k_p,k_p)} \frac{\i(k_s^2-4\xi^2)\mu_p}{\mu\gamma(\xi)\overline{\delta(\xi)}}
\Bigg(
\begin{array}{cc}
	\mu_s^2 & \xi\mu_s \\
	\xi\mu_s & \xi^2
\end{array}		\Bigg)e^{\mathrm{i}\mu_s (z_2-y_2) +\i\xi(y_1-z_1)} \\
:=F^{ss1}(z,y)+F^{ss2}(z,y)
\een
and $R(z,y)=R^{ss}(z,y)+R^{pp}(z,y)+J^{sp}(z,y)+J^{ps}(z,y)$. Then we have $J(z,y)=F(z,y)+R(z,y)$. By the lemma \ref{r_estimate1}-\ref{r_estimate3} and lemma \ref{f_estimate}, the main contribution to the point spread
function is from $F(z,y)$ when $z,y$ far away from $\Gamma_0$. Based on the above argument, we know that $R(z,y)$ becomes small when z,y move away from $\Gamma_0$. Our goal is to show $F(z,y)$ has the similar decay to the elastic fundamental solution $\Im\Phi(z,y)$ as $|z-y|\to\infty$.

\begin{lem} \label{festimate1}
	For any $z,y\in \R_+^2$, when $z=y$
	\ben \label{fe1}
|\Im F_{ii}(z,y)| \geq \frac{1}{4(\lambda+2\mu)} \ , \ i =1 ,2 \\
\Im F_{12}(z,y) = \Im F_{21}(z,y) =0
	\een
	and for $z\neq y$
	\ben
	|F_{ij}(z,y)|&\le \frac{C}{\mu}[(k_s|z-y|)^{-1/2})+(k_s|z-y|^{-1})]
	\een
	where constant $C$ is only dependent on $\kappa$.
\end{lem}
\debproof
We only proof the case of $i=1$, the other ones are similar.
First, we have $\gamma(\xi)\le k_s^2$, $\delta(\xi)\le k_s^4$ and $\mu_p\le\mu_s$ when $\xi\in(-k_p,k_p)$. Then, if $z=y$
\be
-\Im (F^{pp}_{11}+F^{ss1}_{11})\geq\frac{1}{2\pi\mu}\int_{(-k_p,k_p)} \frac{\mu_p}{k_s^2}d\xi \\ =\frac{k_p^2}{2\pi\mu k_s^2}\int_{0}^{\pi} \sin^2(t) dt= \frac{1}{4(\lambda+2\mu)}
\ee
It's left to proof $-\Im F^{ss2}_{11}>0$. If $\xi\in(-k_s,k_s)\bks(-k_p,k_p)$, $\mu_p=\i\sqrt{\xi^2-k_p^2}$. Substituting it into $F^{ss2}$, we have
\be
\hspace{-1.5cm}
F^{ss2}_{11}=\frac{1}{2\pi\mu}\int_{(-k_s,k_s)\bks(-k_p,k_p)} \frac{\mu_s^2\sqrt{\xi^2-k_p^2}(k_s^2-4\xi^2)}{(\xi^2+\i\mu_s\sqrt{\xi^2-k_p^2})(\beta^2-\i4\xi^2\mu_s\sqrt{\xi^2-k_p^2})} d\xi
\ee
let $\alpha=(\xi^2+\i\mu_s\sqrt{\xi^2-k_p^2})(\beta^2-\i4\xi^2\mu_s\sqrt{\xi^2-k_p^2})$. A simple computation show that $\Im \alpha=k_s^2\mu_s\sqrt{\xi^2-k_p^2}(k_s^2-4\xi^2)$. It is easy to see that
\ben
-\Im F^{ss2}_{11}=\frac{k_s^2}{2\pi\mu}\int_{(-k_s,k_s)\bks(-k_p,k_p)} \frac{\mu_s^3(\xi^2-k_p^2)(k_s^2-\xi^2)^2}{|\alpha|^2} d\xi >0
\een

For $z\neq y$, we denot $y-z=|y-z|(\cos\phi,\sin\phi)^T$ for some $0\le\phi\le2\pi$. Then it is easy to see that
\ben
F^{pp}(z,y)=\frac{1}{\mu}\int_{0}^{\pi} A(\theta,\kappa) e^{\i k_s |z-y| \cos(\theta-\phi)}
\een
The phase function $f(\theta)=\cos(\theta-\phi)$ satisfies $f'(\theta)=-\sin(\theta-\phi),f''(\theta)=-\cos(\theta-\phi)$. For any given $0\le\phi\le2\pi$, we can decompose $[0,\pi]$ into several intervals such that in each either $|f''(\theta)|\ge 1/2$ or $|f'(\theta)|\ge 1/2$ and $f'(\theta)$ is monotonous. The amplitude function $A(\theta,\kappa)$ and their derirates are integrable on $[0,\pi]$. Then the estimate for $F_{pp}(z,y)$ follows by using lemma \ref{van}. The estimation of $F^{ss}(z,y)$ can be proved similarly. This completes the proof.
\finproof

By (\ref{q0}), we arrive at the following consequence of Lemma 3.1 and Lemma 3.3 whcih will be used in the next section.
\begin{cor}
	There exists a constant C independent of $k_s$, h such that
	\ben\hspace{-2cm}
	\|F(z,\cdot)\|_{H^{1/2}(\Gamma_D)}+	\|\sigma(F(z,\cdot))\cdot\nu\|_{H^{1/2}(\Gamma_D)}
	\leq  \frac{C}{\mu}(1+kd_D) \\ \hspace{-2cm}
	\|R(z,\cdot)\|_{H^{1/2}(\Gamma_D)}+	\|\sigma(R(z,\cdot))\cdot\nu\|_{H^{1/2}(\Gamma_D)}
	\leq  \frac{C}{\mu}(1+kd_D)(\frac{1}{(k_s h)^{\frac{1}{2n^*}}}+e^{-\sqrt{k_R^2-k_s^2}h})
	\een
	uniformly for $z\in\Om$, where $d_D$ is the diameter of the obstacle D.	
\end{cor}

Now we consider the finite aperture point spread function $J_d(z,y)$:
\be
\int_{-d}^{d} (T_D(x_1,0;z_1,z_2))^T\overline{N(x_1,0;y_1,y_2)}dx_1
\ee
Our aim is to estimate the difference $J(z,y)-J_d(z,y)$. It is easy to see that

\be
\frac{(x_1-z_1)^2}{\rho^2}=\frac{1}{1+\frac{z_2^2}{(x_1-z_1)^2}}\geq \frac{1}{1+\frac{c_3^2 h^2}{(1-c_1)^2 d^2}}:=m(h/d)\\
\frac{z_2^2}{\rho^2}=\frac{1}{1+\frac{(x_1-z_1)^2}{z_2^2}}\leq \frac{1}{1+\frac{(1-c_1)^2 d^2}{c_3^2 h^2}}:=M(h/d)
\ee
where $\rho=\sqrt{(x_1-z_1)^2+z_2^2}$ and $z\in\Omega,x\in \Gamma_0\bks(-d,d)$.
\begin{thm} \label{ap_psf}
	Assume $m(h/d)>(1+\kappa)^2/4$, $M(h/d)<\kappa^2/4$ and $k_s h\geq 1$. Then for $z,y\in\Omega$, we have
	\be \hspace{-2cm}
	|J(z,y)-J_d(z,y)|+k_s^{-1}|\nabla_y(J(z,y)-J_d(z,y))|\leq \frac{C}{\mu} (\frac{h}{ d}+\frac{(k_s h)^{1/2}}{ e^{\sqrt{k_r^2-k_s^2}h}}(\frac{h}{d})^{1/2})
	\ee
	where the constant C is only dependent on $\kappa$.
\end{thm}
\debproof
By lemma \ref{es_ngreen}, lemma \ref{es_dgreen2} and $k_s h\geq 1$, we have
\ben
\Bigg| \int_{d}^{\infty} (T_D(x_1,0;z_1,z_2))^T\overline{N(x_1,0;y_1,y_2)}dx_1
\Bigg| \\
\leq
\frac{C}{\mu}\int_{d}^{\infty}\frac{k_s z_2}{|x-z|}\frac{1}{(k_s|x-z|)^{1/2}}\bigg(
\frac{ y_2}{|x-y|}\frac{1}{(k_s|x-y|)^{1/2}}+e^{-\sqrt{k_r^2-k_s^2}y_2}\bigg) dx_1\\
\leq
\frac{C}{\mu}\int_{(1-c_1)d/h}^{\infty}\frac{1}{(1+t^2)^{3/2}}+\frac{(k_s h)^{1/2}}{(1+t^2)^{3/4}} e^{-\sqrt{k_r^2-k_s^2}h}  dt\\
\leq \frac{C}{\mu} ((\frac{h}{d})^{2}+\frac{(k_s h)^{1/2}}{ e^{\sqrt{k_r^2-k_s^2}h}}(\frac{h}{d})^{1/2})
\een
Here we have used the first inequeality in (\ref{om_bound}). Similarly, we can prove that the estimate for te integral in $[-\infty,-d]$. This shows the estimate for $J(z,y)-J_d(z,y)$. The estimate for $\nabla_y(J(z,y)-J_d(z,y))$ can be proved similarly.
\finproof
By (\ref{q0}) we obtain the following corollary
\begin{cor}
	There exists a constant C independent of $k_s$, h such that
	\ben\hspace{-2cm}
	\|J(z,\cdot)-J_d (z,\cdot)\|_{H^{1/2}(\Gamma_D)}+	\|\sigma(J(z,\cdot)-J_d (z,\cdot))\cdot\nu\|_{H^{1/2}(\Gamma_D)} \\
	\leq \frac{C}{\mu} ((\frac{h}{d})^{2}+\frac{(k_s h)^{1/2}}{ e^{\sqrt{k_r^2-k_s^2}h}}(\frac{h}{d})^{1/2})(1+kd_D)
	\een
	uniformly for $z\in\Om$, where $d_D$ is the diameter of the obstacle D.	
\end{cor}

\section{The resolution analysis}
In this section we study the imaging resolution of the RTM for the Dirichlet boundary obstacle in the half space.
\begin{thm}
For any $z\in\Omega$
\end{thm}
\debproof
By the integral representation, we have,
\be\hspace{-1cm}
u^s_k(x_r,x_s)=\int_{\Gamma_D}(T^{\nu}_y N(y,x_r))^Tu^s_k(y,x_s)-G(x_r,y)(T^{\nu}_y u^s_k(y,x_s)) ds(y)
\ee
where $u^s_k(x,x_s)+N(x,x_s)e_k=0$.
From (\ref{fapsf}) we get for any $z\in\Omega$,
\ben\hspace{-1cm}
v_k(z,x_s)&=&\int_{\Gamma_0^d}(T^{e_2}_{x_r}D(x_r,z))^T\overline{u^s_k(x_r,x_s)}ds(x_r) \\
&=&\int_{\Gamma_D}ds(y)\Big(\int_{\Gamma_0^d}(T^{e_2}_{x_r}D(x_r,z))^T\overline{(T^{\nu}_y N(y,x_r))^T}ds(x_r)\Big)\overline{ u^s_k(y,x_s) }\\
& &-\Big(\int_{\Gamma_0^d}(T^{e_2}_{x_r}D(x_r,z))^T\overline{N(x_r,y)}ds(x_r)\Big)\overline{(T^{\nu}_y u^s_k(y,x_s))} \\
&=&\int_{\Gamma_D}ds(y)\Big(\int_{\Gamma_0^d}(T^{\nu}_y \overline{N(y,x_r)}T^{e_2}_{x_r}D(x_r,z))^T ds(x_r)\Big)\overline{ u^s_k(y,x_s) }\\
& & -\Big(\int_{\Gamma_0^d}(T^{e_2}_{x_r}D(x_r,z))^T\overline{N(x_r,y)}ds(x_r)\Big)\overline{(T^{\nu}_y u^s_k(y,x_s))} \\
&=&\int_{\Gamma_D}ds(y)\Big(\int_{\Gamma_0^d}(T^{\nu}_y [\overline{N(y,x_r)}T^{e_2}_{x_r}D(x_r,z)])^T ds(x_r)\Big)\overline{u^s_k(y,x_s) }\\
& &-\Big(\int_{\Gamma_0^d}(T^{e_2}_{x_r}D(x_r,z))^T\overline{N(x_r,y)}ds(x_r)\Big)\overline{(T^{\nu}_y u^s_k(y,x_s))}\\
&=&\int_{\Gamma_D}ds(y)\Big((T^{\nu}_y J^T_d(z,y))^T \overline{ u^s_k(y,x_s) }
-J_d(z,y)\overline{(T^{\nu}_y u^s_k(y,x_s))}\Big)
\een
where we use the fact $(\sigma_x(A(x))\nu)B=\sigma_x(A(x)B)\nu$ above. By the definition of the imaging function $\hat{I}_d(z)$, we have
\ben\hspace{-1cm}
\hat{I}_d(z)&=&\Im\sum_{k=1}^{2}\int_{\Gamma_0^d}(T^{e_2}_{x_s}D(x_s,z))^Te_k\cdot v_k(z,x_s) ds(x_s)\\
&=&\int_{\Gamma_D} ds(y)\sum_{k=1}^{2}\int_{\Gamma_0^d}(T^{e_2}_{x_s}D(x_s,z))^Te_k\cdot\Big((T^{\nu}_y J^T_d(z,y))^T \overline{ u^s_k(y,x_s) } \\
& &-J_d(z,y)\overline{(T^{\nu}_y u^s_k(y,x_s))}\Big) \\
&=&\Im\int_{\Gamma_D} ds(y)\sum_{k=1}^{2}\mathbf{tr}\Big((T^{\nu}_y J^T_d(z,y))^T\int_{\Gamma_0^d}
\overline{ u^s_k(y,x_s) } e_k^T T^{e_2}_{x_s}D(x_s,z)\\
& &-J_d(z,y)\int_{\Gamma_0^d}\overline{(T^{\nu}_y u^s_k(y,x_s))} e_k^T T^{e_2}_{x_s}D(x_s,z)\Big) \\
&=&\Im\int_{\Gamma_d} ds(y)\mathbf{tr}\Big((T^{\nu}_y J^T_d(z,y))^T \sum_{k=1}^{2} W_k(y,z)\\
& &-J_d(z,y)(T^{\nu}_y \sum_{k=1}^{2}W_k(y,z))\Big) \\
&=&\Im\int_{\Gamma_d} \mathbf{tr}\Big((T^{\nu}_y J^T_d(z,y))^T W(y,z)-J_d(z,y)(T^{\nu}_y W(y,z))\Big)ds(y)
\een
where
\be
W(y,z)=\sum_{k=1}^{2} W_k(y,z) \\
W_k(y,z)= \int_{\Gamma_0^d}
\overline{ u^s_k(y,x_s) } e_k^T (T^{e_2}_{x_s}D(x_s,z))ds(x_s)
\ee
Therefore, $\overline{W_k(y,z)}$ can be viewed as the weighted superposition of $u^s_k(y,x_s)$. Then $\overline{W_k(y,z)}$ satisfies elastic equation
\be
\Delta_e^y \overline{W_k(y,z)} +\omega^2 \overline{W_k(y,z)}=0
\ee
On the boundary of the obstacle $\Gamma_D$, we have
\ben
W(y,z)&=&\sum_{k=1}^{2}\int_{\Gamma_0^d}
 u^s_k(y,x_s)  e_k^T T^{e_2}_{x_s}\overline{D(x_s,z)}ds(x_s) \\
 &=&\sum_{k=1}^{2}\int_{\Gamma_0^d}-N(y,x_s)e_k e_k^T T^{e_2}_{x_s}\overline{D(x_s,z)}ds(x_s)\\
 &=&-\int_{\Gamma_0^d}N(y,x_s) T^{e_2}_{x_s}\overline{D(x_s,z)}ds(x_s) \\
 &=&-\overline{J_d^T(z,y)}
 \een
 Moreover, $T_y^{e_2}\overline{W_k(y,z)}=0$ on $\Gamma_0$ since $T_y^{e_2}u^s_k(y,x_s)=0$ on $\Gamma_0$. Let $W_d(y,z)$ be the scattering solution of the problem
 \be
 & & \Delta_e W_d(y,z) + \omega^2u_q= 0 \ \ \ \ \mbox{in }\R_+^2\bks \bar{D}\\
 & &W_d(y,z)= \overline{F(z,y)}-\overline{J_d^T(z,y)} \ \ \mbox{on} \ \Ga_D  \\ 
 & & \sigma_y(W_d(y,z))\cdot e_2=0 \ \ \mbox{on} \ \Ga_0
 \ee
\be\hspace{-1.5cm}
\hat{I}_d(z)=\Im\mathbf{tr}\int_{\Gamma_d}(T^{\nu}_y J^T_d(z,y))^T \overline{\Psi(y,z)}-J_d(z,y)(T^{\nu}_y\overline{\Psi(y,z)})ds(y)+R_{\hat{I}}(z)
\ee
where
\be\hspace{-1.5cm}
R_{\hat{I}}(z)=\Im\mathbf{tr}\int_{\Gamma_d}(T^{\nu}_y J^T_d(z,y))^T W_d(y,z)-J_d(z,y)(T^{\nu}_y W_d(y,z))ds(y)
\ee
\finproof

\section*{References}
\bibliography{eee}
\end{document}
